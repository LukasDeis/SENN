{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg02FZzDyEqd"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.289130Z",
     "iopub.status.busy": "2020-09-17T01:33:34.288557Z",
     "iopub.status.idle": "2020-09-17T01:33:34.290255Z",
     "shell.execute_reply": "2020-09-17T01:33:34.290746Z"
    },
    "id": "2mapZ9afGJ69"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- fix model creation (preprocessing breaks tensor? https://tensorflow.google.cn/tutorials/load_data/csv)\n",
    "\n",
    "- name all layers\n",
    "\n",
    "- save model for loading afterwards (currently broken, might require named layers)\n",
    "\n",
    "- make sure to mark unaltered cells and annotations as from the original tutorial\n",
    "\n",
    "\n",
    "Maybe:\n",
    "\n",
    "- make a preprocessing model where the preprocessing is done when DiSENN is initialized\n",
    "(for portability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMYQvJuBi7MS"
   },
   "source": [
    "# Classify structured data using Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FaL4wnr22oy"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/preprocessing_layers.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/preprocessing_layers.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nna1tOKxyEqe"
   },
   "source": [
    "This tutorial demonstrates how to classify structured data (e.g. tabular data in a CSV). You will use [Keras](https://www.tensorflow.org/guide/keras) to define the model, and [preprocessing layers](https://keras.io/guides/preprocessing_layers/) as a bridge to map from columns in a CSV to features used to train the model. This tutorial contains complete code to:\n",
    "\n",
    "* Load a CSV file using [Pandas](https://pandas.pydata.org/).\n",
    "* Build an input pipeline to batch and shuffle the rows using [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "* Map from columns in the CSV to features used to train the model using Keras Preprocessing layers.\n",
    "* Build, train, and evaluate a model using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5xkXCicjFQD"
   },
   "source": [
    "Note: This tutorial is similar to [Classify structured data with feature columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns). This version uses new experimental Keras [Preprocessing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing) instead of `tf.feature_column`. Keras Preprocessing Layers are more intuitive, and can be easily included inside your model to simplify deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHxU1FMNpomc"
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "You will use a simplified version of the PetFinder [dataset](https://www.kaggle.com/c/petfinder-adoption-prediction). There are several thousand rows in the CSV. Each row describes a pet, and each column describes an attribute. You will use this information to predict if the pet will be adopted.\n",
    "\n",
    "Following is a description of this dataset. Notice there are both numeric and categorical columns. There is a free text column which you will not use in this tutorial.\n",
    "\n",
    "Column | Description| Feature Type | Data Type\n",
    "------------|--------------------|----------------------|-----------------\n",
    "Type | Type of animal (Dog, Cat) | Categorical | string\n",
    "Age |  Age of the pet | Numerical | integer\n",
    "Breed1 | Primary breed of the pet | Categorical | string\n",
    "Color1 | Color 1 of pet | Categorical | string\n",
    "Color2 | Color 2 of pet | Categorical | string\n",
    "MaturitySize | Size at maturity | Categorical | string\n",
    "FurLength | Fur length | Categorical | string\n",
    "Vaccinated | Pet has been vaccinated | Categorical | string\n",
    "Sterilized | Pet has been sterilized | Categorical | string\n",
    "Health | Health Condition | Categorical | string\n",
    "Fee | Adoption Fee | Numerical | integer\n",
    "Description | Profile write-up for this pet | Text | string\n",
    "PhotoAmt | Total uploaded photos for this pet | Numerical | integer\n",
    "AdoptionSpeed | Speed of adoption | Classification | integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjFbdBldyEqf"
   },
   "source": [
    "## Install and Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.295537Z",
     "iopub.status.busy": "2020-09-17T01:33:34.294862Z",
     "iopub.status.idle": "2020-09-17T01:33:35.675952Z",
     "shell.execute_reply": "2020-09-17T01:33:35.675219Z"
    },
    "id": "S_BdyQlPjfDW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pydot in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pydotplus) (2.4.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (0.14.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datetime in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (4.3)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from datetime) (5.2.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from datetime) (2020.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from zope.interface->datetime) (50.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from packaging) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from packaging) (1.15.0)\n",
      "Requirement already satisfied: keras in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: h5py in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz\n",
    "!pip install datetime\n",
    "!pip install packaging\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install for graph: https://graphviz.gitlab.io/download/\n",
    "maybe follow: https://bobswift.atlassian.net/wiki/spaces/GVIZ/pages/131924165/Graphviz+installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:35.681275Z",
     "iopub.status.busy": "2020-09-17T01:33:35.680588Z",
     "iopub.status.idle": "2020-09-17T01:33:42.191163Z",
     "shell.execute_reply": "2020-09-17T01:33:42.190506Z"
    },
    "id": "LklnLlt6yEqf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from datetime import datetime\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXvBvobayEqi"
   },
   "source": [
    "## Reading in the data\n",
    "\n",
    "the data is read into a pandas dataframe\n",
    "\n",
    "As the real data is sensitive, large and expensive to use,\n",
    "for now I use a dummy dataset about adoption-speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.197790Z",
     "iopub.status.busy": "2020-09-17T01:33:42.197028Z",
     "iopub.status.idle": "2020-09-17T01:33:42.321623Z",
     "shell.execute_reply": "2020-09-17T01:33:42.320979Z"
    },
    "id": "qJ4Ajn-YyEqj"
   },
   "outputs": [],
   "source": [
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
    "                        extract=True, cache_dir='.')\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.343796Z",
     "iopub.status.busy": "2020-09-17T01:33:42.343010Z",
     "iopub.status.idle": "2020-09-17T01:33:42.352803Z",
     "shell.execute_reply": "2020-09-17T01:33:42.353374Z"
    },
    "id": "3uiq4hoIGyXI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  \\\n",
       "0     Short         No         No  Healthy  100   \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0   \n",
       "2    Medium        Yes         No  Healthy    0   \n",
       "3     Short        Yes         No  Healthy  150   \n",
       "4     Short         No         No  Healthy    0   \n",
       "\n",
       "                                         Description  PhotoAmt  AdoptionSpeed  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...         1              2  \n",
       "1  I just found it alone yesterday near my apartm...         2              0  \n",
       "2  Their pregnant mother was dumped by her irresp...         7              3  \n",
       "3  Good guard dog, very alert, active, obedience ...         8              2  \n",
       "4  This handsome yet cute boy is up for adoption....         3              2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3zDbrozyEqq"
   },
   "source": [
    "## Create target variable\n",
    "\n",
    "I have to select the variable I want to train for and drop the columns that are not important or contain that information from the normal dataset.\n",
    "\n",
    "Valid for the example data:\n",
    "The task in the Kaggle competition is to predict the speed at which a pet will be adopted (e.g., in the first week, the first month, the first three months, and so on). Let's simplify this for our tutorial. Here, you will transform this into a binary classification problem, and simply predict whether the pet was adopted, or not.\n",
    "\n",
    "After modifying the label column, 0 will indicate the pet was not adopted, and 1 will indicate it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.358975Z",
     "iopub.status.busy": "2020-09-17T01:33:42.358305Z",
     "iopub.status.idle": "2020-09-17T01:33:42.365151Z",
     "shell.execute_reply": "2020-09-17T01:33:42.364619Z"
    },
    "id": "wmMDc46-yEqq"
   },
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop un-used columns.\n",
    "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp0NCbswyEqs"
   },
   "source": [
    "## Split the dataframe into train, validation, and test\n",
    "\n",
    "The loaded dataset was a single file. It has to be split into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.370622Z",
     "iopub.status.busy": "2020-09-17T01:33:42.369987Z",
     "iopub.status.idle": "2020-09-17T01:33:42.377950Z",
     "shell.execute_reply": "2020-09-17T01:33:42.378325Z"
    },
    "id": "qT6HdyEwyEqt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7383 train examples\n",
      "1846 validation examples\n",
      "2308 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_7uVu-xyEqv"
   },
   "source": [
    "## Create an input pipeline using tf.data\n",
    "\n",
    "The dataframes is wrapped with [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "This is done to easily shuffle and batch the data. \n",
    "\n",
    "If the RAM is not sufficient, tf.data could be used directly to read it from disk in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.383853Z",
     "iopub.status.busy": "2020-09-17T01:33:42.383254Z",
     "iopub.status.idle": "2020-09-17T01:33:42.385369Z",
     "shell.execute_reply": "2020-09-17T01:33:42.384906Z"
    },
    "id": "7r4j-1lRyEqw"
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYxIXH579uS9"
   },
   "source": [
    "The general pipeline for input is finished here.\n",
    "What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.803710Z",
     "iopub.status.busy": "2020-09-17T01:33:42.388965Z",
     "iopub.status.idle": "2020-09-17T01:33:43.830128Z",
     "shell.execute_reply": "2020-09-17T01:33:43.830540Z"
    },
    "id": "tYiNH-QI96Jo"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.836836Z",
     "iopub.status.busy": "2020-09-17T01:33:43.836165Z",
     "iopub.status.idle": "2020-09-17T01:33:43.891242Z",
     "shell.execute_reply": "2020-09-17T01:33:43.890630Z"
    },
    "id": "nFYir6S8HgIJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n",
      "A batch of ages: tf.Tensor([32  6  3  2 36], shape=(5,), dtype=int64)\n",
      "A batch of targets: tf.Tensor([1 1 1 1 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['Age'])\n",
    "print('A batch of targets:', label_batch )\n",
    "\n",
    "# TODO currently this is targeted towards the dummy -set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geqHWW54Hmte"
   },
   "source": [
    "The dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v50jBIuj4gb"
   },
   "source": [
    "## Demonstrate the use of preprocessing layers.\n",
    "\n",
    "I will have to adapt the pipelines when I replace the dummy-code, but afterwards I will be able to input plain string data etc from new data as well.\n",
    "\n",
    "Information about the pre-processing layers for easy access when I am there:\n",
    "\n",
    "*   [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) - Feature-wise normalization of the data.\n",
    "*   [`CategoryEncoding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryEncoding) - Category encoding layer.\n",
    "*   [`StringLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup) - Maps strings from a vocabulary to integer indices.\n",
    "*   [`IntegerLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup) - Maps integers from a vocabulary to integer indices.\n",
    "\n",
    "A list of available preprocessing layers can be found [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twXBSxnT66o8"
   },
   "source": [
    "### Numeric columns\n",
    "A Normalization() layer ensures that each numeric feature has a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OosUh4kTsK_q"
   },
   "source": [
    "The `get_normalization_layer` function returns a keras layer.\n",
    "It applies featurewise normalization to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.896825Z",
     "iopub.status.busy": "2020-09-17T01:33:43.896137Z",
     "iopub.status.idle": "2020-09-17T01:33:43.898143Z",
     "shell.execute_reply": "2020-09-17T01:33:43.898564Z"
    },
    "id": "D6OuEKMMyEq1"
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization()\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.903065Z",
     "iopub.status.busy": "2020-09-17T01:33:43.902172Z",
     "iopub.status.idle": "2020-09-17T01:33:44.842415Z",
     "shell.execute_reply": "2020-09-17T01:33:44.842862Z"
    },
    "id": "MpKgUDyk69bM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[-0.50925547],\n",
       "       [ 0.4294512 ],\n",
       "       [ 1.0552557 ],\n",
       "       [ 0.4294512 ],\n",
       "       [-0.50925547]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_count_col = train_features['PhotoAmt']\n",
    "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
    "layer(photo_count_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWY00YBUx9N"
   },
   "source": [
    "Note: If you many numeric features (hundreds, or more), it is more efficient to concatenate them first and use a single [normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVD--2WZ7vmh"
   },
   "source": [
    "### Categorical columns\n",
    "\n",
    "In the dummy dataset, Type is represented as a string (e.g. 'Dog', or 'Cat'). Sadly, one can not feed strings directly to a model. The preprocessing layer takes care of representing strings as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWlkOPwMsxdv"
   },
   "source": [
    "The `get_category_encoding_layer` function returns a layer, mapping values from a vocabulary to integer indices and one-hot encodes the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:44.850381Z",
     "iopub.status.busy": "2020-09-17T01:33:44.847119Z",
     "iopub.status.idle": "2020-09-17T01:33:44.851920Z",
     "shell.execute_reply": "2020-09-17T01:33:44.852447Z"
    },
    "id": "GmgaeRjlDoUO"
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_values=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = feature_ds.map(index)\n",
    "\n",
    "  # Learn the space of possible indices.\n",
    "  encoder.adapt(feature_ds)\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:44.862532Z",
     "iopub.status.busy": "2020-09-17T01:33:44.861894Z",
     "iopub.status.idle": "2020-09-17T01:33:45.538315Z",
     "shell.execute_reply": "2020-09-17T01:33:45.537801Z"
    },
    "id": "X2t2ff9K8PcT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Type']\n",
    "layer = get_category_encoding_layer('Type', train_ds, 'string')\n",
    "layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6eDongw8knz"
   },
   "source": [
    "Often, you don't want to feed a number directly into the model, but instead use a one-hot encoding of those inputs. Consider raw data that represents a pet's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:45.546513Z",
     "iopub.status.busy": "2020-09-17T01:33:45.545857Z",
     "iopub.status.idle": "2020-09-17T01:33:46.118888Z",
     "shell.execute_reply": "2020-09-17T01:33:46.118367Z"
    },
    "id": "7FjBioQ38oNE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Age']\n",
    "category_encoding_layer = get_category_encoding_layer('Age', train_ds,\n",
    "                                                      'int64', 5)\n",
    "category_encoding_layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiE0glOPkMyh"
   },
   "source": [
    "## Choose and prepare columns to use\n",
    "\n",
    "While we can deal with all types of data, we have to make a list of all columns for each type.\\\n",
    "That way I am able to define which layer needs to be treated how\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.142976Z",
     "iopub.status.busy": "2020-09-17T01:33:46.123925Z",
     "iopub.status.idle": "2020-09-17T01:33:46.180021Z",
     "shell.execute_reply": "2020-09-17T01:33:46.180497Z"
    },
    "id": "Rcv2kQTTo23h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.190642Z",
     "iopub.status.busy": "2020-09-17T01:33:46.186870Z",
     "iopub.status.idle": "2020-09-17T01:33:46.368301Z",
     "shell.execute_reply": "2020-09-17T01:33:46.368852Z"
    },
    "id": "Q3RBa51VkaAn"
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['PhotoAmt', 'Fee']:  # TODO use all headers in UMC set minus the ones I know are something else\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.379746Z",
     "iopub.status.busy": "2020-09-17T01:33:46.378953Z",
     "iopub.status.idle": "2020-09-17T01:33:46.551415Z",
     "shell.execute_reply": "2020-09-17T01:33:46.550766Z"
    },
    "id": "1FOMGfZflhoA"
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers.\n",
    "\n",
    "# TODO at the UMC data, this will be more common, some tests have a categorical scale \n",
    "# However, most of them can just be interpreted as normal numerical feature, so I won't have to overdo it\n",
    "age_col = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
    "encoding_layer = get_category_encoding_layer('Age', train_ds, dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.561248Z",
     "iopub.status.busy": "2020-09-17T01:33:46.560569Z",
     "iopub.status.idle": "2020-09-17T01:33:48.254306Z",
     "shell.execute_reply": "2020-09-17T01:33:48.254765Z"
    },
    "id": "K8C8xyiXm-Ie"
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "categorical_cols = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1'] \n",
    "# TODO replace this by reading the headings from the dataframe\n",
    "\n",
    "for header in categorical_cols:\n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5) # TODO maybe, this line has to be duplicated and slightly changed to accomodate for different max_tokens\n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently I do not think the UMC data needs to be balanced.\n",
    "# It will be evaluated on the same dataset (though a different part of it)\n",
    "# We do not have a large number of samples that are underrepresented, probably causing large inaccura\n",
    "\n",
    "#use:\n",
    "#    https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHSnhz2fyEq3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create, compile, and train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Color1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Color2 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "MaturitySize (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FurLength (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Vaccinated (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Sterilized (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Health (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PhotoAmt (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Fee (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "integer_lookup_1 (IntegerLookup (None, 1)            0           Age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_1 (StringLookup)  (None, 1)            0           Type[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_2 (StringLookup)  (None, 1)            0           Color1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_3 (StringLookup)  (None, 1)            0           Color2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_4 (StringLookup)  (None, 1)            0           Gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_5 (StringLookup)  (None, 1)            0           MaturitySize[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_6 (StringLookup)  (None, 1)            0           FurLength[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_7 (StringLookup)  (None, 1)            0           Vaccinated[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_8 (StringLookup)  (None, 1)            0           Sterilized[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_9 (StringLookup)  (None, 1)            0           Health[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_10 (StringLookup) (None, 1)            0           Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 1)            3           PhotoAmt[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "normalization_2 (Normalization) (None, 1)            3           Fee[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_2 (CategoryEn (None, 5)            0           integer_lookup_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_3 (CategoryEn (None, 4)            0           string_lookup_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_4 (CategoryEn (None, 5)            0           string_lookup_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_5 (CategoryEn (None, 5)            0           string_lookup_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_6 (CategoryEn (None, 4)            0           string_lookup_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_7 (CategoryEn (None, 5)            0           string_lookup_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_8 (CategoryEn (None, 5)            0           string_lookup_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_9 (CategoryEn (None, 5)            0           string_lookup_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_10 (CategoryE (None, 5)            0           string_lookup_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_11 (CategoryE (None, 5)            0           string_lookup_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_12 (CategoryE (None, 5)            0           string_lookup_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 55)           0           normalization_1[0][0]            \n",
      "                                                                 normalization_2[0][0]            \n",
      "                                                                 category_encoding_2[0][0]        \n",
      "                                                                 category_encoding_3[0][0]        \n",
      "                                                                 category_encoding_4[0][0]        \n",
      "                                                                 category_encoding_5[0][0]        \n",
      "                                                                 category_encoding_6[0][0]        \n",
      "                                                                 category_encoding_7[0][0]        \n",
      "                                                                 category_encoding_8[0][0]        \n",
      "                                                                 category_encoding_9[0][0]        \n",
      "                                                                 category_encoding_10[0][0]       \n",
      "                                                                 category_encoding_11[0][0]       \n",
      "                                                                 category_encoding_12[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 6\n",
      "Trainable params: 0\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The first step towards a working model\n",
    "# is our preprocessed input.\n",
    "# As that is a relative complex task, that is regarded it's owy model.\n",
    "\n",
    "preprocessed_layers = layers.Concatenate()(encoded_features)\n",
    "preprocesessing_model = tf.keras.Model(all_inputs, preprocessed_layers)\n",
    "preprocesessing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The main model will contain 2 more sub-models next to the preprocessing one.\n",
    "# One of them represents different concepts, the other one how important a certain concept is,\n",
    "# depending on the input.\n",
    "\n",
    "# As both models create a separate output, to create a prediction, their outputs have to be combined.\n",
    "\n",
    "# A simple way to aggregate the output is to just multiply the concepts with their weights\n",
    "\n",
    "# While the name is *SUM*-aggregator, it is not actually summed RN #TODO rename it\n",
    "# the summing is done in the main model, as the (in the usual sense prmature) output of this function helps interpret the model\n",
    "\n",
    "class SumAggregator:\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"Basic Aggregator that joins the concepts and relevances by summing their products.\n",
    "        -> weights every concept with its relevance the output is the sum\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    @staticmethod\n",
    "    def forward( concepts, relevances):\n",
    "        \"\"\"Forward pass of Sum Aggregator.\n",
    "\n",
    "        Aggregates concepts and relevances and returns the predictions for each class.\n",
    "\n",
    "        Parameters # TODO change this to appropriate TF variants\n",
    "        ----------\n",
    "        concepts : torch.Tensor\n",
    "            Contains the output of the conceptizer with shape (BATCH, NUM_CONCEPTS, DIM_CONCEPT=1).\n",
    "        relevances : torch.Tensor\n",
    "            Contains the output of the parameterizer with shape (BATCH, NUM_CONCEPTS, NUM_CLASSES).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        class_predictions : torch.Tensor\n",
    "            Predictions for each class. Shape - (BATCH, NUM_CLASSES)\n",
    "            \n",
    "        \"\"\"\n",
    "        #permuted = tf.transpose(relevances, perm=[0, 2])  # so that the number of concepts is at the end\n",
    "        #batch_matrix_matrix_product = tf.matmul(permuted, concepts)  # multiply all relevance scores\n",
    "        #       with their corresponding concepts activation\n",
    "        #aggregated = tf.squeeze(batch_matrix_matrix_product)  # squeeze(-1)  # remove the number of concepts\n",
    "        aggregated = tf.math.multiply(concepts, relevances)\n",
    "        \n",
    "        return tf.nn.log_softmax(aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Within the models structure, there are repetetive patterns.\n",
    "\n",
    "# For readability those layers are combined into custom layers:\n",
    "\n",
    "#The first one is a typical combination found in the conceptizer\n",
    "class ConceptizerLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, out_shape):\n",
    "        super(ConceptizerLayer, self).__init__()\n",
    "        #self.inp = layers.Input(shape=(13,))\n",
    "        self.lin = layers.Dense(out_shape, activation='linear')\n",
    "        self.relu = layers.Dense(out_shape, activation='relu')\n",
    "        \n",
    "    def call(self, input_tensor,  training=False):\n",
    "        #x = self.inp(input_tensor)\n",
    "        x = self.lin(input_tensor)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The conceptizer is a submodel of our network.\n",
    "# The idea is, that it learns which combination of inputs are relevant together \n",
    "\n",
    "class Conceptizer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, start_dim):\n",
    "        super(Conceptizer, self).__init__()\n",
    "        self.con0 = ConceptizerLayer(start_dim)\n",
    "        #self.flat = keras.layers.Flatten()\n",
    "        self.con1 = ConceptizerLayer(start_dim/2)\n",
    "        self.con2 = ConceptizerLayer(start_dim/4)\n",
    "        self.lin = layers.Dense(start_dim/4, activation='linear')\n",
    "\n",
    "        \n",
    "    \n",
    "    def call(self, input_tensor,  training=False):\n",
    "        x = self.con0(input_tensor)\n",
    "        #x = self.flat(x)\n",
    "        x = self.con1(x)\n",
    "        x = self.con2(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A combination of layers, common in the parameterizer\n",
    "\n",
    "class ParameterizerLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, out_shape, dropout_rate):\n",
    "        super(ParameterizerLayer, self).__init__()       \n",
    "\n",
    "        self.para_lin = layers.Dense(out_shape, activation='linear')\n",
    "        self.para_drop = layers.Dropout(dropout_rate)\n",
    "        self.para_relu = layers.Dense(out_shape, activation='relu')\n",
    "        \n",
    "    \n",
    "    def call(self, input_tensor,  training=False):\n",
    "        x = self.para_lin(input_tensor)\n",
    "        if training:\n",
    "            x = self.para_drop(x, training=training)\n",
    "        x = self.para_relu(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this sub-model to the network is to assign weights to the conceptizers output.\n",
    "# One could say that every value in its output is a measure of how important a certain concept is.\n",
    "# Here a concept is one output node of the conceptizer,\n",
    "# the Parameterizers output at position x relates to the conceptizers output at that same index (x) \n",
    "\n",
    "class Parameterizer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, hidden_sizes, out_shape, dropout_rate):\n",
    "        super(Parameterizer, self).__init__()\n",
    "        self.para0 = ParameterizerLayer(hidden_sizes[0], dropout_rate)\n",
    "        self.para1 = ParameterizerLayer(hidden_sizes[1], dropout_rate)\n",
    "        self.para2 = ParameterizerLayer(hidden_sizes[2], dropout_rate)\n",
    "        self.para3 = ParameterizerLayer(hidden_sizes[3], dropout_rate)\n",
    "        self.para_lin = layers.Dense(out_shape, activation='linear')\n",
    "        self.para_drop = layers.Dropout(dropout_rate)\n",
    "\n",
    "        \n",
    "    \n",
    "    def call(self, input_tensor,  training=False):\n",
    "        x = self.para0(input_tensor)\n",
    "        x = self.para1(x)\n",
    "        x = self.para2(x)\n",
    "        x = self.para3(x)\n",
    "        x = self.para_lin(x)\n",
    "        if training:\n",
    "            x = self.para_drop(x, training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this model in non-standard in many ways, a custom loss function is necessary\n",
    "# As we would like to track and reference those values outside of the model, they are defined here \n",
    "# TODO is that actually necessary?\n",
    "\n",
    "#TODO make them the actually matching loss and metric!\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This class stores the network itself\n",
    "\n",
    "# Basically: the input is preprocessed into normalized scalars and fed into \n",
    "# a) The conceptizer to learn which features go together to form underlying structures\n",
    "# b) The parameterizer to learn which concept is important in what situation.\n",
    "# a and b are then combined by the aggregator\n",
    "# the aggregators output is summed up to produce the prediction\n",
    "\n",
    "#TODO replace the singe neuron at the end by a sum function.\n",
    "\n",
    "class DiSENN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, hidden_sizes, preprocessing_model, dropout_rate):\n",
    "        \n",
    "        #general (superclass) model constructor\n",
    "        super(DiSENN, self).__init__()\n",
    "        \n",
    "        #preprocess the input\n",
    "        self.input_layers = preprocessing_model\n",
    "        \n",
    "        # the main model that learns the concepts\n",
    "        input_features = 512\n",
    "        self.conceptizer = Conceptizer(input_features)  # out: input_features / 4\n",
    "\n",
    "        \n",
    "        # The model that gives a weight per feature (parameterizer)\n",
    "        out_shape = input_features/4\n",
    "        self.parameterizer = Parameterizer(hidden_sizes, out_shape, dropout_rate)  # out: out_shape\n",
    "\n",
    "        \n",
    "        # The way to combine the activation and weights (aggregator)\n",
    "        num_classes = 13 #TODO update\n",
    "        self.aggregator = SumAggregator(num_classes)\n",
    "        \n",
    "        self.finalizer = layers.Dense(1, activation='linear')\n",
    "        \n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        \n",
    "        pre_processed = self.input_layers(input_tensor) \n",
    "        \n",
    "        concepts = self.conceptizer(pre_processed)\n",
    "        \n",
    "        relevances = self.parameterizer(pre_processed)\n",
    "        \n",
    "        #aggregate the output\n",
    "        aggr_output = self.aggregator.forward(concepts, relevances)\n",
    "        \n",
    "        finalized = self.finalizer(aggr_output)\n",
    "        return finalized\n",
    "    \n",
    "    # customize the train function, base code from:\n",
    "    # https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "            print(\"Warning: sample weight is not currently supported!\")\n",
    "        else:\n",
    "            x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = keras.losses.binary_crossentropy(y, y_pred)        \n",
    "               \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred) # TODO support sample_weight=sample_weight\n",
    "        \n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [loss_tracker, mae_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network as object has to be initialized before use, the hidden_sizes are important to determine hoe big the network is going to be.\n",
    "# hidden_sizes must be exactly 4 elements long, each number gives the size of a hidden layer in the parameterizer.\n",
    "hidden_sizes = [11, 5, 5, 22]  # TODO fix this to actual size\n",
    "model = DiSENN(hidden_sizes, preprocesessing_model, dropout_rate=0.1)     \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "      #loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),  # used to be from_logits=True\n",
    "      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6mNMfG6yEq5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's visualize our connectivity graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:48.331722Z",
     "iopub.status.busy": "2020-09-17T01:33:48.330973Z",
     "iopub.status.idle": "2020-09-17T01:33:48.644924Z",
     "shell.execute_reply": "2020-09-17T01:33:48.645441Z"
    },
    "id": "Y7Bkx4c7yEq5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback, used for the animated, interactive tensorboard visualizatioon\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "#This should plot the exhaustive graph, but is a bit unreliable\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CED6OStLyEq7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:48.652006Z",
     "iopub.status.busy": "2020-09-17T01:33:48.651331Z",
     "iopub.status.idle": "2020-09-17T01:33:52.227177Z",
     "shell.execute_reply": "2020-09-17T01:33:52.226654Z"
    },
    "id": "OQfE3PC6yEq8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 2/29 [=>............................] - ETA: 22s - loss: 0.0000e+00 - mae: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 1.6406s). Check your callbacks.\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - mae: 0.0000e+00 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23f6eef97c0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=[tensorboard_callback])\n",
    "\n",
    "# for this to work, properly I need to define my own loss - function like here:\n",
    "# https://www.tensorflow.org/guide/keras/custom_layers_and_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.231471Z",
     "iopub.status.busy": "2020-09-17T01:33:52.230837Z",
     "iopub.status.idle": "2020-09-17T01:33:52.288853Z",
     "shell.execute_reply": "2020-09-17T01:33:52.289388Z"
    },
    "id": "T8N2uAdU2Cni"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mae: 0.0000e+00\n",
      "Accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21468), started 6:24:42 ago. (Use '!kill 21468' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2e8bbf1aed7eeb43\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2e8bbf1aed7eeb43\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize model in an interactive way\n",
    "\n",
    "%reload_ext tensorboard\n",
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZMnTKaCZda",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inference on new data\n",
    "\n",
    "As the model contains all important parts, it should be able to work on any file of the right format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xkOlK8Zweeh"
   },
   "source": [
    "The model should be saved such that it can just be reloaded later.\\\n",
    "I will follow the tutorial [here](https://www.tensorflow.org/tutorials/keras/save_and_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.296839Z",
     "iopub.status.busy": "2020-09-17T01:33:52.296192Z",
     "iopub.status.idle": "2020-09-17T01:33:56.352943Z",
     "shell.execute_reply": "2020-09-17T01:33:56.352275Z"
    },
    "id": "QH9Zy1sBvwOH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_pet_classifier\\assets\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A3155E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A306790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A329B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A346040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A306DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A337790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A346670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A337D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A2FFCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A3590D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000023F7A329670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.save('my_pet_classifier')\n",
    "reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D973plJrdwQ9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are just two things you need to do:\n",
    "\n",
    "1.   Wrap scalars into a list so as to have a batch dimension (models only process batches of data, not single samples)\n",
    "2.   Call `convert_to_tensor` on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:56.360094Z",
     "iopub.status.busy": "2020-09-17T01:33:56.359400Z",
     "iopub.status.idle": "2020-09-17T01:33:56.669531Z",
     "shell.execute_reply": "2020-09-17T01:33:56.669015Z"
    },
    "id": "rKq4pxtdDa7i",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:71 return_outputs_and_add_losses\n        outputs, losses = fn(inputs, *args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:167 wrap_with_training_arg\n        return tf_utils.smart_cond(\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py:64 smart_cond\n        return smart_module.smart_cond(\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:56 smart_cond\n        return false_fn()\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:170 <lambda>\n        lambda: replace_training_and_call(False))\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:165 replace_training_and_call\n        return wrapped_call(*args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780 __call__\n        result = self._call(*args, **kwds)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:814 _call\n        results = self._stateful_fn(*args, **kwds)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2828 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3213 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3065 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:986 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:251 restored_function_body\n        raise ValueError(\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (2 total):\n        * {'Type': <tf.Tensor 'input_tensor_11:0' shape=(None, 1) dtype=string>, 'Age': <tf.Tensor 'input_tensor:0' shape=(None, 1) dtype=int32>, 'Breed1': <tf.Tensor 'input_tensor_1:0' shape=(None, 1) dtype=string>, 'Gender': <tf.Tensor 'input_tensor_6:0' shape=(None, 1) dtype=string>, 'Color1': <tf.Tensor 'input_tensor_2:0' shape=(None, 1) dtype=string>, 'Color2': <tf.Tensor 'input_tensor_3:0' shape=(None, 1) dtype=string>, 'MaturitySize': <tf.Tensor 'input_tensor_8:0' shape=(None, 1) dtype=string>, 'FurLength': <tf.Tensor 'input_tensor_5:0' shape=(None, 1) dtype=string>, 'Vaccinated': <tf.Tensor 'input_tensor_12:0' shape=(None, 1) dtype=string>, 'Sterilized': <tf.Tensor 'input_tensor_10:0' shape=(None, 1) dtype=string>, 'Health': <tf.Tensor 'input_tensor_7:0' shape=(None, 1) dtype=string>, 'Fee': <tf.Tensor 'input_tensor_4:0' shape=(None, 1) dtype=int32>, 'PhotoAmt': <tf.Tensor 'input_tensor_9:0' shape=(None, 1) dtype=int32>}\n        * False\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Vaccinated')}\n        * True\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='Vaccinated')}\n        * True\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='Vaccinated')}\n        * False\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Vaccinated')}\n        * False\n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-53-7c1f267ad33f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[0minput_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msample\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreloaded_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[0mprob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msigmoid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    128\u001B[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001B[0;32m    129\u001B[0m           method.__name__))\n\u001B[1;32m--> 130\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    131\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    132\u001B[0m   return tf_decorator.make_decorator(\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1597\u001B[0m           \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1598\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_predict_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1599\u001B[1;33m             \u001B[0mtmp_batch_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1600\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1601\u001B[0m               \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    778\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 780\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    781\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    812\u001B[0m       \u001B[1;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m       \u001B[1;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 814\u001B[1;33m       \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    815\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    816\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2826\u001B[0m     \u001B[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2828\u001B[1;33m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2829\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3208\u001B[0m           \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_signature\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3209\u001B[0m           and call_context_key in self._function_cache.missed):\n\u001B[1;32m-> 3210\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_define_function_with_shape_relaxation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3211\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3212\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_define_function_with_shape_relaxation\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3139\u001B[0m           expand_composites=True)\n\u001B[0;32m   3140\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3141\u001B[1;33m     graph_function = self._create_graph_function(\n\u001B[0m\u001B[0;32m   3142\u001B[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001B[0;32m   3143\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marg_relaxed\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrank_only_cache_key\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3063\u001B[0m     \u001B[0marg_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbase_arg_names\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmissing_arg_names\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3064\u001B[0m     graph_function = ConcreteFunction(\n\u001B[1;32m-> 3065\u001B[1;33m         func_graph_module.func_graph_from_py_func(\n\u001B[0m\u001B[0;32m   3066\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3067\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_python_function\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m    984\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    985\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 986\u001B[1;33m       \u001B[0mfunc_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    987\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    988\u001B[0m       \u001B[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    598\u001B[0m         \u001B[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    599\u001B[0m         \u001B[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 600\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    601\u001B[0m     \u001B[0mweak_wrapped_fn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mref\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwrapped_fn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    602\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    971\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    972\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ag_error_metadata\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 973\u001B[1;33m               \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    974\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    975\u001B[0m               \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:71 return_outputs_and_add_losses\n        outputs, losses = fn(inputs, *args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:167 wrap_with_training_arg\n        return tf_utils.smart_cond(\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py:64 smart_cond\n        return smart_module.smart_cond(\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:56 smart_cond\n        return false_fn()\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:170 <lambda>\n        lambda: replace_training_and_call(False))\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\utils.py:165 replace_training_and_call\n        return wrapped_call(*args, **kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780 __call__\n        result = self._call(*args, **kwds)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:814 _call\n        results = self._stateful_fn(*args, **kwds)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2828 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3213 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3065 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:986 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:251 restored_function_body\n        raise ValueError(\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (2 total):\n        * {'Type': <tf.Tensor 'input_tensor_11:0' shape=(None, 1) dtype=string>, 'Age': <tf.Tensor 'input_tensor:0' shape=(None, 1) dtype=int32>, 'Breed1': <tf.Tensor 'input_tensor_1:0' shape=(None, 1) dtype=string>, 'Gender': <tf.Tensor 'input_tensor_6:0' shape=(None, 1) dtype=string>, 'Color1': <tf.Tensor 'input_tensor_2:0' shape=(None, 1) dtype=string>, 'Color2': <tf.Tensor 'input_tensor_3:0' shape=(None, 1) dtype=string>, 'MaturitySize': <tf.Tensor 'input_tensor_8:0' shape=(None, 1) dtype=string>, 'FurLength': <tf.Tensor 'input_tensor_5:0' shape=(None, 1) dtype=string>, 'Vaccinated': <tf.Tensor 'input_tensor_12:0' shape=(None, 1) dtype=string>, 'Sterilized': <tf.Tensor 'input_tensor_10:0' shape=(None, 1) dtype=string>, 'Health': <tf.Tensor 'input_tensor_7:0' shape=(None, 1) dtype=string>, 'Fee': <tf.Tensor 'input_tensor_4:0' shape=(None, 1) dtype=int32>, 'PhotoAmt': <tf.Tensor 'input_tensor_9:0' shape=(None, 1) dtype=int32>}\n        * False\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Vaccinated')}\n        * True\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='Vaccinated')}\n        * True\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='Vaccinated')}\n        * False\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (2 total):\n        * {'Age': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Age'), 'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Breed1'), 'Color1': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color1'), 'Color2': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Color2'), 'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/Fee'), 'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/FurLength'), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Gender'), 'Health': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Health'), 'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/MaturitySize'), 'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name='input_tensor/PhotoAmt'), 'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Sterilized'), 'Type': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Type'), 'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name='input_tensor/Vaccinated')}\n        * False\n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "# TODO this does not work\n",
    "\n",
    "sample = {\n",
    "    'Type': 'Cat',\n",
    "    'Age': 3,\n",
    "    'Breed1': 'Tabby',\n",
    "    'Gender': 'Male',\n",
    "    'Color1': 'Black',\n",
    "    'Color2': 'White',\n",
    "    'MaturitySize': 'Small',\n",
    "    'FurLength': 'Short',\n",
    "    'Vaccinated': 'No',\n",
    "    'Sterilized': 'No',\n",
    "    'Health': 'Healthy',\n",
    "    'Fee': 100,\n",
    "    'PhotoAmt': 2,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = reloaded_model.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing_layers.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}