{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg02FZzDyEqd"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.289130Z",
     "iopub.status.busy": "2020-09-17T01:33:34.288557Z",
     "iopub.status.idle": "2020-09-17T01:33:34.290255Z",
     "shell.execute_reply": "2020-09-17T01:33:34.290746Z"
    },
    "id": "2mapZ9afGJ69"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- fix model creation (preprocessing breaks tensor? https://tensorflow.google.cn/tutorials/load_data/csv)\n",
    "\n",
    "- name all layers\n",
    "\n",
    "- save model for loading afterwards (currently broken, might require named layers, might clash with concatenate layer)\n",
    "\n",
    "- make sure to mark unaltered cells and annotations as from the original tutorial\n",
    "\n",
    "- make sure the GPU is used\n",
    "\n",
    "- make model .fit and .evaluate work (if it does not)\n",
    "\n",
    "- make callbacks work during fitting (in custom loop)\n",
    "\n",
    "\n",
    "Maybe:\n",
    "\n",
    "- make a preprocessing model where the preprocessing is done when SENN is initialized\n",
    "(for portability)\n",
    "\n",
    "- augment data by just adding random noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMYQvJuBi7MS"
   },
   "source": [
    "# Classify structured data using Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FaL4wnr22oy"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/preprocessing_layers.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/preprocessing_layers.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nna1tOKxyEqe"
   },
   "source": [
    "This tutorial demonstrates how to classify structured data (e.g. tabular data in a CSV). You will use [Keras](https://www.tensorflow.org/guide/keras) to define the model, and [preprocessing layers](https://keras.io/guides/preprocessing_layers/) as a bridge to map from columns in a CSV to features used to train the model. This tutorial contains complete code to:\n",
    "\n",
    "* Load a CSV file using [Pandas](https://pandas.pydata.org/).\n",
    "* Build an input pipeline to batch and shuffle the rows using [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "* Map from columns in the CSV to features used to train the model using Keras Preprocessing layers.\n",
    "* Build, train, and evaluate a model using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5xkXCicjFQD"
   },
   "source": [
    "Note: This tutorial is similar to [Classify structured data with feature columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns). This version uses new experimental Keras [Preprocessing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing) instead of `tf.feature_column`. Keras Preprocessing Layers are more intuitive, and can be easily included inside your model to simplify deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHxU1FMNpomc"
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "For designing the network I use a smaller and simpler dataset. \n",
    "\n",
    "It is a simplified version of the PetFinder [dataset](https://www.kaggle.com/c/petfinder-adoption-prediction). There are several thousand rows in the CSV. Each row describes a pet, and each column describes an attribute. \n",
    "\n",
    "The goal is to predict if the pet will be adopted.\n",
    "\n",
    "Following is a description of this dataset. \\\n",
    "Notice there are both numeric and categorical columns. \n",
    "\n",
    "The free text column will be ignored.\n",
    "\n",
    "Column | Description| Feature Type | Data Type\n",
    "------------|--------------------|----------------------|-----------------\n",
    "Type | Type of animal (Dog, Cat) | Categorical | string\n",
    "Age |  Age of the pet | Numerical | integer\n",
    "Breed1 | Primary breed of the pet | Categorical | string\n",
    "Color1 | Color 1 of pet | Categorical | string\n",
    "Color2 | Color 2 of pet | Categorical | string\n",
    "MaturitySize | Size at maturity | Categorical | string\n",
    "FurLength | Fur length | Categorical | string\n",
    "Vaccinated | Pet has been vaccinated | Categorical | string\n",
    "Sterilized | Pet has been sterilized | Categorical | string\n",
    "Health | Health Condition | Categorical | string\n",
    "Fee | Adoption Fee | Numerical | integer\n",
    "Description | Profile write-up for this pet | Text | string\n",
    "PhotoAmt | Total uploaded photos for this pet | Numerical | integer\n",
    "AdoptionSpeed | Speed of adoption | Classification | integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjFbdBldyEqf"
   },
   "source": [
    "## Install and Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.295537Z",
     "iopub.status.busy": "2020-09-17T01:33:34.294862Z",
     "iopub.status.idle": "2020-09-17T01:33:35.675952Z",
     "shell.execute_reply": "2020-09-17T01:33:35.675219Z"
    },
    "id": "S_BdyQlPjfDW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pydot in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pydotplus) (2.4.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (0.14.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datetime in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (4.3)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from datetime) (5.2.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from datetime) (2020.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from zope.interface->datetime) (50.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from packaging) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from packaging) (1.15.0)\n",
      "Requirement already satisfied: keras in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz\n",
    "!pip install datetime\n",
    "!pip install packaging\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install for graph: https://graphviz.gitlab.io/download/\n",
    "maybe follow: https://bobswift.atlassian.net/wiki/spaces/GVIZ/pages/131924165/Graphviz+installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from datetime import datetime\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXvBvobayEqi"
   },
   "source": [
    "## Reading in the data\n",
    "\n",
    "The data is read into a pandas dataframe\n",
    "\n",
    "Again:\\\n",
    "As the real data is sensitive, large and expensive to use,\n",
    "for now I use a dummy dataset about adoption-speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.197790Z",
     "iopub.status.busy": "2020-09-17T01:33:42.197028Z",
     "iopub.status.idle": "2020-09-17T01:33:42.321623Z",
     "shell.execute_reply": "2020-09-17T01:33:42.320979Z"
    },
    "id": "qJ4Ajn-YyEqj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
    "                        extract=True, cache_dir='.')\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.343796Z",
     "iopub.status.busy": "2020-09-17T01:33:42.343010Z",
     "iopub.status.idle": "2020-09-17T01:33:42.352803Z",
     "shell.execute_reply": "2020-09-17T01:33:42.353374Z"
    },
    "id": "3uiq4hoIGyXI",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  \\\n",
       "0     Short         No         No  Healthy  100   \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0   \n",
       "2    Medium        Yes         No  Healthy    0   \n",
       "3     Short        Yes         No  Healthy  150   \n",
       "4     Short         No         No  Healthy    0   \n",
       "\n",
       "                                         Description  PhotoAmt  AdoptionSpeed  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...         1              2  \n",
       "1  I just found it alone yesterday near my apartm...         2              0  \n",
       "2  Their pregnant mother was dumped by her irresp...         7              3  \n",
       "3  Good guard dog, very alert, active, obedience ...         8              2  \n",
       "4  This handsome yet cute boy is up for adoption....         3              2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3zDbrozyEqq"
   },
   "source": [
    "## Creating the target variable\n",
    "\n",
    "I have to select the variable I want to train for and drop the columns that are not important or contain that information from the normal dataset.\n",
    "\n",
    "Valid for the example data:\n",
    "The task in the Kaggle competition was to predict the speed at which a pet will be adopted (e.g., in the first week, the first month, the first three months, and so on). Let's simplify this for our purposes. It is transformed into a binary classification problem:\n",
    "I simply predict whether the pet was adopted, or not.\n",
    "\n",
    "After modifying the label column, 0 will indicate the pet was not adopted, and 1 will indicate it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.358975Z",
     "iopub.status.busy": "2020-09-17T01:33:42.358305Z",
     "iopub.status.idle": "2020-09-17T01:33:42.365151Z",
     "shell.execute_reply": "2020-09-17T01:33:42.364619Z"
    },
    "id": "wmMDc46-yEqq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop un-used columns. (including our now target which can not be used for training)\n",
    "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataframe = dataframe.drop(columns=['Fee', 'PhotoAmt','Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "#                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1'])\n",
    "\n",
    "#for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  PhotoAmt  target  \n",
       "0     Short         No         No  Healthy  100         1       1  \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0         2       1  \n",
       "2    Medium        Yes         No  Healthy    0         7       1  \n",
       "3     Short        Yes         No  Healthy  150         8       1  \n",
       "4     Short         No         No  Healthy    0         3       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp0NCbswyEqs"
   },
   "source": [
    "## Spliting the dataframe into train, validation, and test\n",
    "\n",
    "The loaded dataset was a single file. It has to be split into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.370622Z",
     "iopub.status.busy": "2020-09-17T01:33:42.369987Z",
     "iopub.status.idle": "2020-09-17T01:33:42.377950Z",
     "shell.execute_reply": "2020-09-17T01:33:42.378325Z"
    },
    "id": "qT6HdyEwyEqt",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7383 train examples\n",
      "1846 validation examples\n",
      "2308 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_7uVu-xyEqv"
   },
   "source": [
    "## Input pipeline\n",
    "\n",
    "The dataframe is wrapped with [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "This is done to easily shuffle and batch the data. \n",
    "\n",
    "If the RAM is not sufficient, tf.data could be used directly to read it from disk in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.383853Z",
     "iopub.status.busy": "2020-09-17T01:33:42.383254Z",
     "iopub.status.idle": "2020-09-17T01:33:42.385369Z",
     "shell.execute_reply": "2020-09-17T01:33:42.384906Z"
    },
    "id": "7r4j-1lRyEqw",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=1):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYxIXH579uS9"
   },
   "source": [
    "The general pipeline for input is finished here.\n",
    "What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.803710Z",
     "iopub.status.busy": "2020-09-17T01:33:42.388965Z",
     "iopub.status.idle": "2020-09-17T01:33:43.830128Z",
     "shell.execute_reply": "2020-09-17T01:33:43.830540Z"
    },
    "id": "tYiNH-QI96Jo",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.836836Z",
     "iopub.status.busy": "2020-09-17T01:33:43.836165Z",
     "iopub.status.idle": "2020-09-17T01:33:43.891242Z",
     "shell.execute_reply": "2020-09-17T01:33:43.890630Z"
    },
    "id": "nFYir6S8HgIJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n",
      "A batch of ages: tf.Tensor([24  2 10  2 48], shape=(5,), dtype=int64)\n",
      "A batch of targets: tf.Tensor([1 1 1 1 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['Age'])\n",
    "print('A batch of targets:', label_batch )\n",
    "\n",
    "# TODO currently this is targeted towards the dummy -set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geqHWW54Hmte"
   },
   "source": [
    "The dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v50jBIuj4gb"
   },
   "source": [
    "## Preprocessing layers\n",
    "\n",
    "I will have to adapt the pipelines when I replace the dummy-code, but afterwards I will be able to input plain string data etc from new data as well.\n",
    "\n",
    "Information about the pre-processing layers for easy access when I am there:\n",
    "\n",
    "*   [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) - Feature-wise normalization of the data.\n",
    "*   [`CategoryEncoding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryEncoding) - Category encoding layer.\n",
    "*   [`StringLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup) - Maps strings from a vocabulary to integer indices.\n",
    "*   [`IntegerLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup) - Maps integers from a vocabulary to integer indices.\n",
    "\n",
    "A list of available preprocessing layers can be found [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twXBSxnT66o8"
   },
   "source": [
    "### Numeric columns\n",
    "A Normalization() layer ensures that each numeric feature has a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OosUh4kTsK_q"
   },
   "source": [
    "The `get_normalization_layer` function returns a keras layer.\n",
    "It applies featurewise normalization to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.896825Z",
     "iopub.status.busy": "2020-09-17T01:33:43.896137Z",
     "iopub.status.idle": "2020-09-17T01:33:43.898143Z",
     "shell.execute_reply": "2020-09-17T01:33:43.898564Z"
    },
    "id": "D6OuEKMMyEq1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization()\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.903065Z",
     "iopub.status.busy": "2020-09-17T01:33:43.902172Z",
     "iopub.status.idle": "2020-09-17T01:33:44.842415Z",
     "shell.execute_reply": "2020-09-17T01:33:44.842862Z"
    },
    "id": "MpKgUDyk69bM",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[-0.5041111 ],\n",
       "       [ 0.44493753],\n",
       "       [ 1.7103356 ],\n",
       "       [ 0.44493753],\n",
       "       [-0.5041111 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_count_col = train_features['PhotoAmt']\n",
    "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
    "layer(photo_count_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWY00YBUx9N"
   },
   "source": [
    "TODO: If I will indeed have many numeric features (hundreds, or more), it would be more efficient to concatenate them first and use a single [normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVD--2WZ7vmh"
   },
   "source": [
    "### Categorical columns\n",
    "\n",
    "In the dummy dataset, Type is represented as a string (e.g. 'Dog', or 'Cat'). Sadly, one can not feed strings directly to a model. The preprocessing layer takes care of representing strings as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWlkOPwMsxdv"
   },
   "source": [
    "The `get_category_encoding_layer` function returns a layer, mapping values from a vocabulary to integer indices and one-hot encodes the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:44.850381Z",
     "iopub.status.busy": "2020-09-17T01:33:44.847119Z",
     "iopub.status.idle": "2020-09-17T01:33:44.851920Z",
     "shell.execute_reply": "2020-09-17T01:33:44.852447Z"
    },
    "id": "GmgaeRjlDoUO",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_values=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = feature_ds.map(index)\n",
    "\n",
    "  # Learn the space of possible indices.\n",
    "  encoder.adapt(feature_ds)\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:44.862532Z",
     "iopub.status.busy": "2020-09-17T01:33:44.861894Z",
     "iopub.status.idle": "2020-09-17T01:33:45.538315Z",
     "shell.execute_reply": "2020-09-17T01:33:45.537801Z"
    },
    "id": "X2t2ff9K8PcT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Type']\n",
    "layer = get_category_encoding_layer('Type', train_ds, 'string')\n",
    "layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6eDongw8knz"
   },
   "source": [
    "Often, you don't want to feed a number directly into the model, but instead use a one-hot encoding of those inputs. Consider raw data that represents a pet's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:45.546513Z",
     "iopub.status.busy": "2020-09-17T01:33:45.545857Z",
     "iopub.status.idle": "2020-09-17T01:33:46.118888Z",
     "shell.execute_reply": "2020-09-17T01:33:46.118367Z"
    },
    "id": "7FjBioQ38oNE",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Age']\n",
    "category_encoding_layer = get_category_encoding_layer('Age', train_ds,\n",
    "                                                      'int64', 5)\n",
    "category_encoding_layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiE0glOPkMyh"
   },
   "source": [
    "## Choosing and preparing columns to use\n",
    "\n",
    "While we can deal with all types of data, we have to make a list of all columns for each type.\\\n",
    "That way I am able to define which layer needs to be treated how\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.142976Z",
     "iopub.status.busy": "2020-09-17T01:33:46.123925Z",
     "iopub.status.idle": "2020-09-17T01:33:46.180021Z",
     "shell.execute_reply": "2020-09-17T01:33:46.180497Z"
    },
    "id": "Rcv2kQTTo23h",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.190642Z",
     "iopub.status.busy": "2020-09-17T01:33:46.186870Z",
     "iopub.status.idle": "2020-09-17T01:33:46.368301Z",
     "shell.execute_reply": "2020-09-17T01:33:46.368852Z"
    },
    "id": "Q3RBa51VkaAn",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['PhotoAmt', 'Fee']:  # TODO use all headers in UMC set minus the ones I know are something else\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.379746Z",
     "iopub.status.busy": "2020-09-17T01:33:46.378953Z",
     "iopub.status.idle": "2020-09-17T01:33:46.551415Z",
     "shell.execute_reply": "2020-09-17T01:33:46.550766Z"
    },
    "id": "1FOMGfZflhoA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers.\n",
    "\n",
    "# TODO at the UMC data, this will be more common, some tests have a categorical scale \n",
    "# However, most of them can just be interpreted as normal numerical feature, so I won't have to overdo it\n",
    "age_col = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
    "encoding_layer = get_category_encoding_layer('Age', train_ds, dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.561248Z",
     "iopub.status.busy": "2020-09-17T01:33:46.560569Z",
     "iopub.status.idle": "2020-09-17T01:33:48.254306Z",
     "shell.execute_reply": "2020-09-17T01:33:48.254765Z"
    },
    "id": "K8C8xyiXm-Ie",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "categorical_cols = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1'] \n",
    "# TODO replace this by reading the headings from the dataframe and substracting the hardcoded headings (that I know are something else))\n",
    "\n",
    "for header in categorical_cols:\n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5) # TODO maybe, this line has to be duplicated and slightly changed to accomodate for different max_tokens\n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Currently I do not think the UMC data needs to be balanced.\n",
    "# It will be evaluated on the same dataset (though a different part of it)\n",
    "# We do not have a large number of samples that are underrepresented, probably causing large inaccura\n",
    "\n",
    "#use:\n",
    "#    https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHSnhz2fyEq3"
   },
   "source": [
    "## The model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Color1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Color2 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "MaturitySize (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FurLength (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Vaccinated (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Sterilized (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Health (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PhotoAmt (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Fee (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "integer_lookup_1 (IntegerLookup (None, 1)            0           Age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_1 (StringLookup)  (None, 1)            0           Type[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_2 (StringLookup)  (None, 1)            0           Color1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_3 (StringLookup)  (None, 1)            0           Color2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_4 (StringLookup)  (None, 1)            0           Gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_5 (StringLookup)  (None, 1)            0           MaturitySize[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_6 (StringLookup)  (None, 1)            0           FurLength[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_7 (StringLookup)  (None, 1)            0           Vaccinated[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_8 (StringLookup)  (None, 1)            0           Sterilized[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_9 (StringLookup)  (None, 1)            0           Health[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_10 (StringLookup) (None, 1)            0           Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 1)            3           PhotoAmt[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "normalization_2 (Normalization) (None, 1)            3           Fee[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_2 (CategoryEn (None, 5)            0           integer_lookup_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_3 (CategoryEn (None, 4)            0           string_lookup_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_4 (CategoryEn (None, 5)            0           string_lookup_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_5 (CategoryEn (None, 5)            0           string_lookup_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_6 (CategoryEn (None, 4)            0           string_lookup_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_7 (CategoryEn (None, 5)            0           string_lookup_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_8 (CategoryEn (None, 5)            0           string_lookup_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_9 (CategoryEn (None, 5)            0           string_lookup_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_10 (CategoryE (None, 5)            0           string_lookup_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_11 (CategoryE (None, 5)            0           string_lookup_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_12 (CategoryE (None, 5)            0           string_lookup_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 55)           0           normalization_1[0][0]            \n",
      "                                                                 normalization_2[0][0]            \n",
      "                                                                 category_encoding_2[0][0]        \n",
      "                                                                 category_encoding_3[0][0]        \n",
      "                                                                 category_encoding_4[0][0]        \n",
      "                                                                 category_encoding_5[0][0]        \n",
      "                                                                 category_encoding_6[0][0]        \n",
      "                                                                 category_encoding_7[0][0]        \n",
      "                                                                 category_encoding_8[0][0]        \n",
      "                                                                 category_encoding_9[0][0]        \n",
      "                                                                 category_encoding_10[0][0]       \n",
      "                                                                 category_encoding_11[0][0]       \n",
      "                                                                 category_encoding_12[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 6\n",
      "Trainable params: 0\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The first step towards a working model\n",
    "# is our preprocessed input.\n",
    "# As that is a relative complex task, that is regarded it's owy model.\n",
    "\n",
    "preprocessed_layers = layers.Concatenate()(encoded_features) #encoded_features\n",
    "preprocesessing_model = tf.keras.Model(all_inputs, preprocessed_layers)\n",
    "preprocesessing_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the models structure, there are repetetive patterns.\n",
    "\n",
    "For readability those layers are combined into custom layers and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# A combination of layers, common in the parameterizer\n",
    "\n",
    "class ParameterizerLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, out_shape, dropout_rate):\n",
    "        super(ParameterizerLayer, self).__init__()\n",
    "        self.para_lin = layers.Dense(out_shape, activation='linear')\n",
    "        self.para_drop = layers.Dropout(dropout_rate)\n",
    "        self.para_relu = layers.Dense(out_shape, activation=tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "        \n",
    "    \n",
    "    def call(self, input_tensor,  training=False):\n",
    "        x = self.para_lin(input_tensor)\n",
    "        if training:\n",
    "            x = self.para_drop(x, training=training)\n",
    "        x = self.para_relu(x)        \n",
    "        return x\n",
    "    \n",
    "# should minimize robustness loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functional model def\n",
    "\n",
    "#TODO no more static sizes\n",
    "batch_size = 1\n",
    "preprocessed_inputs_shape = 55 \n",
    "dropout_rate=0.1\n",
    "hidden_sizes = [40, 20, 15, 5]  # TODO fix this to actual size\n",
    "out_shape = preprocessed_inputs_shape\n",
    "\n",
    "input_shape = [batch_size, preprocessed_inputs_shape]\n",
    "input_layer = layers.Input(batch_shape = input_shape)\n",
    "\n",
    "x = input_layer\n",
    "###Parameterizer###\n",
    "x = ParameterizerLayer(hidden_sizes[0], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[1], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[2], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[3], dropout_rate)(x)\n",
    "x = layers.Dense(out_shape, activation='linear')(x)\n",
    "relevances = layers.Dropout(rate=dropout_rate, name=\"relevances\")(x)\n",
    "\n",
    "###Conceptizer###\n",
    "concepts = layers.Lambda(lambda t: t, name=\"concepts\")(input_layer)\n",
    "\n",
    "###Aggregator###\n",
    "\n",
    "aggregated = layers.multiply([relevances, concepts])\n",
    "aggregated = layers.Lambda(lambda t: tf.keras.backend.sum(t, axis=-1))(aggregated)\n",
    "aggregated = layers.Lambda(lambda t: tf.keras.activations.sigmoid(t), name=\"output\")(aggregated)\n",
    "\n",
    "out_layer = [aggregated, concepts, relevances]\n",
    "\n",
    "functional_model = tf.keras.Model(inputs=input_layer, outputs=out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom fun with more inputs\n",
    "\n",
    "def get_custom_loss(some_other_argument):\n",
    "    \n",
    "    def custom_loss(y_true, y_pred): \n",
    "        loss = 0\n",
    "        loss = loss + some_other_argument\n",
    "        loss = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        return loss\n",
    "    \n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_loss(y_true, y_pred):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(1, 55)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer (Parameteri (1, 40)              3880        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_1 (Paramete (1, 20)              1240        parameterizer_layer[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_2 (Paramete (1, 15)              555         parameterizer_layer_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_3 (Paramete (1, 5)               110         parameterizer_layer_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (1, 55)              330         parameterizer_layer_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "relevances (Dropout)            (1, 55)              0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concepts (Lambda)               (1, 55)              0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (1, 55)              0           relevances[0][0]                 \n",
      "                                                                 concepts[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (1,)                 0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (1,)                 0           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,115\n",
      "Trainable params: 6,115\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_dict = {\n",
    "    \"relevances\": keras.losses.mean_absolute_error, #get_custom_loss(some_other_argument=1),\n",
    "    \"output\": keras.losses.binary_crossentropy, #tf.nn.log_poisson_loss,\n",
    "    \"concepts\": zero_loss\n",
    "}\n",
    "\n",
    "functional_model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=loss_dict,\n",
    "    loss_weights=[1, 5, 0],\n",
    "    metrics= ['accuracy']\n",
    ")  \n",
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do pre-processing of data separately\n",
    "processed_train_ds = train_ds.map(\n",
    "  lambda x, y: (\n",
    "      tf.cast(preprocesessing_model(x), dtype=tf.float32), \n",
    "      tf.cast(y, dtype=tf.float32)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:48.331722Z",
     "iopub.status.busy": "2020-09-17T01:33:48.330973Z",
     "iopub.status.idle": "2020-09-17T01:33:48.644924Z",
     "shell.execute_reply": "2020-09-17T01:33:48.645441Z"
    },
    "id": "Y7Bkx4c7yEq5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback, used for the animated, interactive tensorboard visualizatioon\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "#This should plot the exhaustive graph, but is a bit unreliable\n",
    "tf.keras.utils.plot_model(functional_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ParameterizerLayer has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/10\n",
      "   1/7383 [..............................] - ETA: 0s - loss: 0.7931 - output_loss: 0.7931 - concepts_loss: 0.0000e+00 - relevances_loss: 1.0021 - output_accuracy: 0.0000e+00 - concepts_accuracy: 0.0000e+00 - relevances_accuracy: 0.0000e+00WARNING:tensorflow:From c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0452s). Check your callbacks.\n",
      "7383/7383 [==============================] - 7s 1ms/step - loss: 0.5336 - output_loss: 0.5336 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7215 - output_accuracy: 0.7379 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7383/7383 [==============================] - 6s 870us/step - loss: 0.5164 - output_loss: 0.5164 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7182 - output_accuracy: 0.7473 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "7383/7383 [==============================] - 7s 881us/step - loss: 0.5116 - output_loss: 0.5116 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7182 - output_accuracy: 0.7516 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7383/7383 [==============================] - 7s 899us/step - loss: 0.5125 - output_loss: 0.5125 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7133 - output_accuracy: 0.7569 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "7383/7383 [==============================] - 7s 891us/step - loss: 0.5132 - output_loss: 0.5132 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7180 - output_accuracy: 0.7483 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "7383/7383 [==============================] - 7s 918us/step - loss: 0.5091 - output_loss: 0.5091 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7218 - output_accuracy: 0.7544 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "7383/7383 [==============================] - 7s 908us/step - loss: 0.5042 - output_loss: 0.5042 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7213 - output_accuracy: 0.7581 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "7383/7383 [==============================] - 7s 924us/step - loss: 0.5082 - output_loss: 0.5082 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7220 - output_accuracy: 0.7512 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "7383/7383 [==============================] - 7s 911us/step - loss: 0.5036 - output_loss: 0.5036 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7244 - output_accuracy: 0.7513 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "7383/7383 [==============================] - 7s 890us/step - loss: 0.5053 - output_loss: 0.5053 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7210 - output_accuracy: 0.7525 - concepts_accuracy: 0.0624 - relevances_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c256fa65b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.print(\"processed_train_ds shape:\", processed_train_ds.take(0))\n",
    "functional_model.fit(processed_train_ds, epochs=10, callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\\\n",
    "1: The error refers to this:\\\n",
    "I provide a gradient for every input feature (55),\\\n",
    "    that makes sense as my parameterizer has output-dimensions of one per input.\\\n",
    "However, it wants a second dimension of 10,\\\n",
    "    which is de dimension of the FIRST layer of the parameterizer, NOT the last.\\\n",
    "I do not understand that or what to do about it.\\\n",
    "\\\n",
    "2: How can I constrain the output to something from 0 to 1 without disconnecting the graph?\\\n",
    "3: Why are there only 18 trainable weights when the model has 55 preprocessed inputs\\\n",
    "   and the parameterizer has more than 18 outputs?\\\n",
    "4: How do I scale up to a larger batch_size, given that now I have to use the [0] trick to make it work?\\\n",
    "5: Why is the classification loss so weird sometimes target = predicted should give 0, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6mNMfG6yEq5"
   },
   "source": [
    "Let's visualize our connectivity graph:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pre-processing of data separately\n",
    "processed_test_ds = test_ds.map(\n",
    "  lambda x, y: (\n",
    "      tf.cast(preprocesessing_model(x), dtype=tf.float32), \n",
    "      tf.cast(y, dtype=tf.float32)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.231471Z",
     "iopub.status.busy": "2020-09-17T01:33:52.230837Z",
     "iopub.status.idle": "2020-09-17T01:33:52.288853Z",
     "shell.execute_reply": "2020-09-17T01:33:52.289388Z"
    },
    "id": "T8N2uAdU2Cni",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2308/2308 [==============================] - 1s 632us/step - loss: 0.5254 - output_loss: 0.5254 - concepts_loss: 0.0000e+00 - relevances_loss: 0.7051 - output_accuracy: 0.7474 - concepts_accuracy: 0.0672 - relevances_accuracy: 0.0000e+00\n",
      "Accuracy [0.5254480838775635, 0.5254480838775635, 0.0, 0.7050992846488953, 0.7474003434181213, 0.06715771555900574, 0.0]\n"
     ]
    }
   ],
   "source": [
    "accuracy = functional_model.evaluate(processed_test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide x and y of test set\n",
    "x = []\n",
    "y_true = []\n",
    "\n",
    "for x_var, y_var in processed_test_ds:\n",
    "    x.append(x_var)\n",
    "    y_true.append(y_var[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### based on coursera util.py for metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "\n",
    "def get_true_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 1))\n",
    "\n",
    "\n",
    "def get_true_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 0))\n",
    "\n",
    "\n",
    "def get_false_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 1))\n",
    "\n",
    "\n",
    "def get_false_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 0))\n",
    "\n",
    "\n",
    "def get_performance_metrics(y, pred, class_labels, tp=get_true_pos,\n",
    "                            tn=get_true_neg, fp=get_false_pos,\n",
    "                            fn=get_false_neg,\n",
    "                            acc=None, prevalence=None, spec=None,\n",
    "                            sens=None, ppv=None, npv=None, auc=None, f1=None,\n",
    "                            threshold= 0.5):\n",
    "\n",
    "    columns = [\"Label\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"Prevalence\",\n",
    "               \"Sensitivity\",\n",
    "               \"Specificity\", \"PPV\", \"NPV\", \"AUC\", \"F1\", \"Threshold\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in range(len(class_labels)): ## i is the concerning class in each iteration\n",
    "        class_pred = pred[i]\n",
    "        count_preds = len(class_pred) # the class was tried to predict as often as a prediction was made\n",
    "        class_y = np.repeat(i, count_preds) # we filter for one class only anyway -> all the same\n",
    "        tf.print(\"class_y:\", class_y)\n",
    "        tf.print(\"class_pred:\", class_pred)\n",
    "        ## construct df for all data concerning class\n",
    "        row_data = {\n",
    "            \"Label\": class_labels[i],\n",
    "            \"TP\": round(tp(class_y, class_pred),3) if tp != None else \"Not Defined\",\n",
    "            \"TN\": round(tn(class_y, class_pred),3) if tn != None else \"Not Defined\",\n",
    "            \"FP\": round(fp(class_y, class_pred),3) if fp != None else \"Not Defined\",\n",
    "            \"FN\": round(fn(class_y, class_pred),3) if fn != None else \"Not Defined\",\n",
    "            \"Accuracy\": round(acc(class_y, class_pred, threshold), 3) if acc != None else \"Not Defined\",\n",
    "            \"Prevalence\": round(prevalence(class_y), 3) if prevalence != None else \"Not Defined\",\n",
    "            \"Sensitivity\": round(sens(class_y, class_pred, threshold), 3) if sens != None else \"Not Defined\",\n",
    "            \"Specificity\": round(spec(class_y, class_pred, threshold), 3) if spec != None else \"Not Defined\",\n",
    "            \"PPV\": round(ppv(class_y, class_pred, threshold), 3) if ppv != None else \"Not Defined\",\n",
    "            \"NPV\": round(npv(class_y, class_pred, threshold), 3) if npv != None else \"Not Defined\",\n",
    "            \"AUC\": round(auc(class_y, class_pred), 3) if auc != None else \"Not Defined\",\n",
    "            \"F1\": round(f1(class_y, class_pred > threshold), 3) if f1 != None else \"Not Defined\",\n",
    "            \"Threshold\": round(threshold, 3)\n",
    "        }\n",
    "        tf.print(\"One row of metrics:\", row_data)\n",
    "        df = df.append(row_data, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_confidence_intervals(class_labels, statistics):\n",
    "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
    "    for i in range(len(class_labels)):\n",
    "        mean = statistics.mean(axis=1)[i]\n",
    "        max_ = np.quantile(statistics, .95, axis=1)[i]\n",
    "        min_ = np.quantile(statistics, .05, axis=1)[i]\n",
    "        df.loc[class_labels[i]] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_curve(gt, pred, target_names, curve='roc'):\n",
    "    for i in range(len(target_names)):\n",
    "        if curve == 'roc':\n",
    "            curve_function = roc_curve\n",
    "            auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" AUC: %.3f \" % auc_roc\n",
    "            xlabel = \"False positive rate\"\n",
    "            ylabel = \"True positive rate\"\n",
    "            a, b, _ = curve_function(gt[:, i], pred[:, i])\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.plot(a, b, label=label)\n",
    "            plt.xlabel(xlabel)\n",
    "            plt.ylabel(ylabel)\n",
    "\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n",
    "        elif curve == 'prc':\n",
    "            precision, recall, _ = precision_recall_curve(gt[:, i], pred[:, i])\n",
    "            average_precision = average_precision_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" Avg.: %.3f \" % average_precision\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.step(recall, precision, where='post', label=label)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "y_pred = []\n",
    "\n",
    "for x_var in x:\n",
    "    y_pred.append(functional_model.predict(x_var)[0][0])\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#tf.print(y_pred)\n",
    "### binarize the classifications\n",
    "#threshold = 0.5\n",
    "#y_pred_binary = np.where(y_pred > threshold, 1.0, 0.0)\n",
    "#tf.print(\"y_pred_binary:\", y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "fpr_keras, tpr_keras, thresholds_rf = roc_curve(y_true, y_pred)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['not adopted', 'adopted']\n",
    "\n",
    "y_pred_sorted = []\n",
    "for i in range(len(class_labels)):\n",
    "    ## filter data for the target class\n",
    "    class_y_indices = [c for c,x in enumerate(y_true) if x==i] ##where is a prediction made about the class\n",
    "    class_pred = [y_pred[i] for i in class_y_indices] # predictions for this class\n",
    "    array = np.array(class_pred) # needs to be np.array\n",
    "    y_pred_sorted.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true_array: array([1., 1., 1., ..., 0., 1., 1.], dtype=float32)\n",
      "len class_labels: 2\n",
      "class_y: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0])\n",
      "class_pred: array([6.6812313e-01, 9.4723916e-01, 9.3153918e-01, 5.3820419e-01,\n",
      "       9.2363101e-01, 5.0217181e-01, 4.1330001e-01, 4.2505652e-01,\n",
      "       5.6564480e-01, 3.2623589e-01, 4.9317065e-01, 4.3950894e-01,\n",
      "       6.4407432e-01, 9.2187148e-01, 6.6396111e-01, 4.7701731e-01,\n",
      "       7.3762256e-01, 9.1483074e-01, 5.0537395e-01, 8.9283407e-01,\n",
      "       7.1788710e-01, 7.3952550e-01, 4.4843534e-01, 6.6769814e-01,\n",
      "       7.0538139e-01, 3.6125529e-01, 8.6883998e-01, 8.7345910e-01,\n",
      "       6.2070268e-01, 4.8185998e-01, 4.0824300e-01, 4.3773958e-01,\n",
      "       5.2491426e-01, 9.0727448e-01, 7.1162415e-01, 6.7085838e-01,\n",
      "       6.7349386e-01, 4.6542969e-01, 7.7668452e-01, 6.4438939e-01,\n",
      "       4.2071617e-01, 9.1316032e-01, 1.6565043e-01, 4.8002341e-01,\n",
      "       9.1814959e-01, 5.0137949e-01, 4.6641353e-01, 8.6707473e-01,\n",
      "       5.5304837e-01, 5.7783556e-01, 6.9053870e-01, 9.0268886e-01,\n",
      "       8.0736291e-01, 6.6134340e-01, 6.6017514e-01, 4.6718183e-01,\n",
      "       9.0599167e-01, 8.7601846e-01, 7.5226510e-01, 6.8450272e-01,\n",
      "       3.7317327e-01, 8.5227466e-01, 5.5387312e-01, 4.6845639e-01,\n",
      "       6.9174981e-01, 4.9873781e-01, 7.5622797e-01, 6.9303447e-01,\n",
      "       9.2841291e-01, 7.9789782e-01, 3.5147178e-01, 5.8983999e-01,\n",
      "       6.3762772e-01, 3.8641241e-01, 9.4556439e-01, 7.5029248e-01,\n",
      "       5.8440161e-01, 8.8650799e-01, 6.9112492e-01, 7.0075703e-01,\n",
      "       7.5347954e-01, 6.1660707e-01, 6.8248266e-01, 7.6807326e-01,\n",
      "       3.9221466e-01, 7.5669193e-01, 5.1089668e-01, 4.2850432e-01,\n",
      "       9.6936071e-01, 6.5679669e-01, 9.5001352e-01, 3.8660532e-01,\n",
      "       4.5914835e-01, 4.8381025e-01, 4.1146821e-01, 4.3918198e-01,\n",
      "       4.9484438e-01, 4.8582166e-01, 9.8913872e-01, 4.3918198e-01,\n",
      "       4.6114826e-01, 5.3810889e-01, 9.2148232e-01, 4.6518141e-01,\n",
      "       6.6394037e-01, 4.3947589e-01, 6.2396288e-01, 8.5751534e-01,\n",
      "       3.6255801e-01, 6.6899824e-01, 5.1904839e-01, 6.7032111e-01,\n",
      "       7.2385144e-01, 6.6717911e-01, 4.8690763e-01, 7.5968802e-01,\n",
      "       6.8394327e-01, 5.5717218e-01, 5.6317389e-01, 8.4838432e-01,\n",
      "       5.5612367e-01, 8.5810679e-01, 8.7078953e-01, 8.4669340e-01,\n",
      "       5.2673399e-01, 2.9801059e-01, 8.5752666e-01, 9.8608613e-01,\n",
      "       8.5836709e-01, 9.6329165e-01, 6.6909218e-01, 5.4598975e-01,\n",
      "       4.3846893e-01, 4.4075477e-01, 4.0802485e-01, 8.6164320e-01,\n",
      "       8.4480733e-01, 4.9788070e-01, 4.5616522e-01, 5.8274066e-01,\n",
      "       9.2941689e-01, 4.7579038e-01, 6.7019677e-01, 8.2641101e-01,\n",
      "       5.5400437e-01, 5.3619301e-01, 3.5848862e-01, 4.6953061e-01,\n",
      "       7.1324170e-01, 7.4679482e-01, 8.0997479e-01, 2.4153745e-01,\n",
      "       5.5582339e-01, 3.9901692e-01, 9.1487217e-01, 7.1461266e-01,\n",
      "       5.4040599e-01, 5.7709235e-01, 8.2482004e-01, 4.2509836e-01,\n",
      "       6.7685759e-01, 7.8721225e-01, 7.8039074e-01, 8.4132779e-01,\n",
      "       7.9416037e-01, 6.8263412e-01, 7.2815645e-01, 5.0477713e-01,\n",
      "       5.1965004e-01, 4.8016024e-01, 7.0217538e-01, 5.5135399e-01,\n",
      "       6.9897580e-01, 7.1057630e-01, 7.6812363e-01, 4.1076219e-01,\n",
      "       7.8494012e-01, 5.1228136e-01, 7.0506644e-01, 2.8839725e-01,\n",
      "       7.4536371e-01, 6.0981703e-01, 5.6461757e-01, 5.4970729e-01,\n",
      "       4.7787127e-01, 6.0373366e-01, 8.8128573e-01, 8.7524819e-01,\n",
      "       6.0273451e-01, 4.4887787e-01, 1.9022840e-01, 3.7098113e-01,\n",
      "       6.8964875e-01, 8.1114113e-01, 5.5152988e-01, 4.2084610e-01,\n",
      "       5.8111686e-01, 4.2428508e-01, 9.0990186e-01, 6.8517911e-01,\n",
      "       4.9178895e-01, 8.5524786e-01, 5.0598776e-01, 5.1100022e-01,\n",
      "       5.4479206e-01, 4.0957865e-01, 8.2872558e-01, 8.0576652e-01,\n",
      "       5.5604774e-01, 3.4207875e-01, 5.9207088e-01, 7.3483682e-01,\n",
      "       5.5556631e-01, 8.2369006e-01, 8.8353020e-01, 7.7446699e-01,\n",
      "       8.8818479e-01, 3.9628971e-01, 8.9185369e-01, 3.9060080e-01,\n",
      "       5.0986189e-01, 4.6760362e-01, 8.2229531e-01, 4.2905736e-01,\n",
      "       5.6879187e-01, 6.4859265e-01, 6.6255933e-01, 7.9477954e-01,\n",
      "       5.1705658e-01, 8.0891085e-01, 2.3991376e-01, 6.5412843e-01,\n",
      "       6.5947902e-01, 6.9744194e-01, 5.5166513e-01, 4.6305174e-01,\n",
      "       8.1484550e-01, 7.6287270e-01, 6.4768243e-01, 6.5495062e-01,\n",
      "       6.2943429e-01, 5.0235140e-01, 6.3770401e-01, 6.0449296e-01,\n",
      "       3.5326403e-01, 6.3626641e-01, 8.6973083e-01, 4.9709785e-01,\n",
      "       7.1701932e-01, 4.1415778e-01, 5.9829807e-01, 8.0385864e-01,\n",
      "       4.5065296e-01, 5.2887470e-01, 6.1990112e-01, 5.6706601e-01,\n",
      "       4.3926758e-01, 4.6038631e-01, 4.8102963e-01, 5.4857141e-01,\n",
      "       8.8650799e-01, 6.7924529e-01, 6.0895532e-01, 4.7222134e-01,\n",
      "       8.2651412e-01, 7.3864889e-01, 6.2876588e-01, 5.7363242e-01,\n",
      "       8.6614060e-01, 7.8069508e-01, 7.3588604e-01, 4.3945488e-01,\n",
      "       6.0274839e-01, 4.6555448e-01, 5.2151263e-01, 7.2662979e-01,\n",
      "       6.6238737e-01, 3.4214824e-01, 7.0181072e-01, 6.4739239e-01,\n",
      "       4.1189644e-01, 8.9090306e-01, 9.8019063e-01, 7.9920197e-01,\n",
      "       3.8308704e-01, 4.7780129e-01, 7.2824103e-01, 7.2133547e-01,\n",
      "       5.5358756e-01, 8.1707537e-01, 5.9207088e-01, 4.2610365e-01,\n",
      "       6.8234587e-01, 5.5143827e-01, 4.1488725e-01, 7.0075095e-01,\n",
      "       7.7256429e-01, 4.0581626e-01, 6.6128117e-01, 7.7072060e-01,\n",
      "       5.5488741e-01, 8.2481503e-01, 9.4953507e-01, 3.8883504e-01,\n",
      "       6.0267913e-01, 4.7330058e-01, 3.7688604e-01, 4.2143908e-01,\n",
      "       9.2154694e-01, 5.8358526e-01, 4.8015878e-01, 7.7166224e-01,\n",
      "       4.2897639e-01, 3.3945200e-01, 5.8170795e-01, 5.2973115e-01,\n",
      "       9.2530239e-01, 4.9176070e-01, 6.8488795e-01, 4.3265945e-01,\n",
      "       8.2020414e-01, 7.9526341e-01, 5.6825930e-01, 8.2890779e-01,\n",
      "       9.2311841e-01, 7.3271376e-01, 3.9741531e-01, 9.4791418e-01,\n",
      "       8.6013210e-01, 3.2695687e-01, 4.6254539e-01, 4.6994627e-01,\n",
      "       5.6236112e-01, 7.7425146e-01, 9.4748354e-01, 3.1827563e-01,\n",
      "       7.0137501e-02, 9.4025350e-01, 5.1335692e-01, 8.6266077e-01,\n",
      "       6.0600394e-01, 4.6365783e-01, 5.8427948e-01, 4.3097144e-01,\n",
      "       8.5618079e-01, 6.6895127e-01, 9.6535325e-01, 6.0654753e-01,\n",
      "       7.4711430e-01, 9.5003903e-01, 7.1090454e-01, 3.4296507e-01,\n",
      "       5.0728619e-01, 6.1033636e-01, 9.5198917e-01, 3.7597319e-01,\n",
      "       9.6118712e-01, 5.4130536e-01, 7.7621269e-01, 7.9826045e-01,\n",
      "       7.3023963e-01, 7.3559952e-01, 5.7218385e-01, 2.9511690e-01,\n",
      "       8.2801795e-01, 4.5808554e-01, 5.1500821e-01, 9.3135285e-01,\n",
      "       4.5408490e-01, 4.1099724e-01, 4.7901332e-01, 5.7553256e-01,\n",
      "       6.8748951e-01, 3.6735666e-01, 6.6424954e-01, 8.6276650e-01,\n",
      "       6.7584932e-01, 6.7088962e-01, 8.5449255e-01, 7.4636030e-01,\n",
      "       6.1298668e-01, 7.0824003e-01, 6.6955686e-01, 3.4299383e-01,\n",
      "       8.1085652e-01, 4.9581465e-01, 4.7368976e-01, 7.7072859e-01,\n",
      "       6.3691205e-01, 5.4752159e-01, 7.9152977e-01, 4.8414114e-01,\n",
      "       9.2427361e-01, 4.6911180e-01, 7.6027167e-01, 5.9656471e-01,\n",
      "       4.2429507e-01, 5.3672093e-01, 9.2427361e-01, 5.9475994e-01,\n",
      "       8.8202977e-01, 3.8688254e-01, 6.2522668e-01, 3.7951928e-01,\n",
      "       8.5651886e-01, 5.1610726e-01, 7.0605111e-01, 5.7163602e-01,\n",
      "       8.9398944e-01, 4.1927218e-01, 8.9007187e-01, 4.1404992e-01,\n",
      "       9.0839964e-01, 8.4669340e-01, 3.1907177e-01, 8.7625611e-01,\n",
      "       6.7267513e-01, 4.8992139e-01, 8.4193021e-01, 7.3435974e-01,\n",
      "       5.4598975e-01, 3.8308704e-01, 4.0421939e-01, 7.8495562e-01,\n",
      "       5.8888000e-01, 9.0407205e-01, 2.9598713e-01, 9.6035892e-01,\n",
      "       7.1547389e-01, 5.7466680e-01, 8.4601474e-01, 7.7597404e-01,\n",
      "       8.4462547e-01, 9.5081109e-01, 4.6824831e-01, 3.4789741e-01,\n",
      "       5.5926496e-01, 7.5731540e-01, 4.7502977e-01, 5.9655529e-01,\n",
      "       5.1978093e-01, 7.4918646e-01, 6.8200755e-01, 5.7242590e-01,\n",
      "       4.7940543e-01, 9.0599167e-01, 5.6546098e-01, 4.9555588e-01,\n",
      "       8.4265435e-01, 5.5136198e-01, 8.8761491e-01, 4.0211457e-01,\n",
      "       3.5147178e-01, 3.9060080e-01, 4.8754239e-01, 6.3698667e-01,\n",
      "       7.7224267e-01, 3.8249248e-01, 6.6894543e-01, 5.9580934e-01,\n",
      "       4.3493214e-01, 4.9827418e-01, 2.9312137e-01, 4.0194419e-01,\n",
      "       7.8361064e-01, 4.8515356e-01, 6.5114784e-01, 5.7392389e-01,\n",
      "       3.6526752e-01, 4.6361375e-01, 5.5598080e-01, 5.1590335e-01,\n",
      "       5.7510984e-01, 8.4480733e-01, 7.1194494e-01, 5.7909030e-01,\n",
      "       9.1877663e-01, 8.9111292e-01, 6.6821891e-01, 6.6520393e-01,\n",
      "       6.9558144e-01, 7.8840590e-01, 9.1511273e-01, 3.6748523e-01,\n",
      "       5.0963384e-01, 4.2071617e-01, 6.3666737e-01, 3.9386287e-01,\n",
      "       4.2143908e-01, 6.5918005e-01, 4.7203791e-01, 4.6101880e-01,\n",
      "       5.4444259e-01, 7.9697883e-01, 5.6271911e-01, 6.5069360e-01,\n",
      "       7.0137548e-01, 4.8015878e-01, 3.0935478e-01, 4.2137098e-01,\n",
      "       7.3472100e-01, 8.9268017e-01, 5.9507501e-01, 4.0393159e-01,\n",
      "       9.3641245e-01, 7.3280048e-01, 5.1522285e-01, 3.5552081e-01,\n",
      "       7.7290314e-01, 8.1420135e-01, 5.0222141e-01, 7.7751058e-01,\n",
      "       7.0333701e-01, 4.7965479e-01, 3.3507735e-01, 4.5370719e-01,\n",
      "       8.1061900e-01, 4.2610365e-01, 5.2662575e-01, 7.5218672e-01,\n",
      "       3.9509726e-01, 4.5662296e-01, 5.3068358e-01, 7.8505242e-01,\n",
      "       9.4355309e-01, 9.6911526e-01, 5.4177952e-01, 9.7355872e-01,\n",
      "       9.0794778e-01, 8.1447434e-01, 6.6333604e-01, 4.1609323e-01,\n",
      "       6.7247033e-01, 7.8114259e-01, 5.5890179e-01, 6.2435842e-01,\n",
      "       4.3347710e-01, 6.3226181e-01, 7.0418888e-01, 4.0962738e-01,\n",
      "       5.4416692e-01, 3.8225049e-01, 5.8666736e-01, 5.3912717e-01,\n",
      "       8.7119836e-01, 8.6345112e-01, 5.1326430e-01, 7.3570210e-01,\n",
      "       7.0772123e-01, 4.0281305e-01, 4.2798427e-01, 7.3459780e-01,\n",
      "       4.4277301e-01, 5.1097172e-01, 7.2824645e-01, 4.2897639e-01,\n",
      "       4.8381239e-01, 3.4316492e-01, 9.3418467e-01, 4.0547884e-01,\n",
      "       4.7146660e-01, 3.8162035e-01, 5.4145658e-01, 4.9276796e-01,\n",
      "       3.9331409e-01, 7.1119499e-01, 2.4320245e-02, 9.2933393e-01,\n",
      "       3.9060080e-01, 6.3739127e-01, 8.5656148e-01, 9.4167483e-01,\n",
      "       4.8504302e-01, 5.0075758e-01, 8.8214576e-01, 6.4914620e-01,\n",
      "       6.1331862e-01, 5.8200467e-01, 6.3141161e-01, 4.7593734e-01,\n",
      "       4.9301255e-01, 4.3673000e-01, 9.9375969e-01, 3.9741531e-01,\n",
      "       7.9294842e-01, 4.9362102e-01, 7.3380345e-01, 6.1130524e-04,\n",
      "       3.7426144e-01, 6.1837667e-01, 8.4047580e-01, 6.5441453e-01,\n",
      "       9.5614266e-01, 8.5395920e-01, 8.9455712e-01, 7.7607024e-01,\n",
      "       6.7769307e-01, 3.9741531e-01, 7.6451123e-01, 8.2044077e-01,\n",
      "       6.1135411e-01, 9.4037676e-01, 7.8877163e-01, 6.4671057e-01,\n",
      "       8.7083113e-01, 4.0004429e-01, 4.8286626e-01, 7.0501995e-01,\n",
      "       6.6478527e-01, 4.7777489e-01, 6.2820566e-01, 5.0075758e-01,\n",
      "       8.3111787e-01, 6.1649448e-01, 8.2560116e-01, 4.7136065e-01,\n",
      "       6.7514932e-01, 3.2642013e-01, 6.2264919e-01, 4.2993823e-01,\n",
      "       5.4097563e-01, 6.0588485e-01, 7.0205271e-01, 7.6713717e-01,\n",
      "       8.3488947e-01, 5.9953362e-01, 7.2121280e-01, 6.7154384e-01,\n",
      "       5.1206708e-01, 6.9224179e-01, 5.0812453e-01, 9.0941024e-01,\n",
      "       4.6157497e-01, 3.5452610e-01, 4.0258479e-01, 4.7875816e-01,\n",
      "       8.7547708e-01, 8.0644715e-01, 5.2045888e-01, 3.6296344e-01,\n",
      "       7.0124710e-01, 4.0134060e-01, 9.3515420e-01, 9.2652863e-01,\n",
      "       4.8215634e-01], dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One row of metrics: {'AUC': 'Not Defined',\n",
      " 'Accuracy': 'Not Defined',\n",
      " 'F1': 'Not Defined',\n",
      " 'FN': 0,\n",
      " 'FP': 448,\n",
      " 'Label': 'not adopted',\n",
      " 'NPV': 'Not Defined',\n",
      " 'PPV': 'Not Defined',\n",
      " 'Prevalence': 'Not Defined',\n",
      " 'Sensitivity': 'Not Defined',\n",
      " 'Specificity': 'Not Defined',\n",
      " 'TN': 197,\n",
      " 'TP': 0,\n",
      " 'Threshold': 0.5}\n",
      "class_y: array([1, 1, 1, ..., 1, 1, 1])\n",
      "class_pred: array([0.52844495, 0.6059406 , 0.8004652 , ..., 0.7823363 , 0.9710828 ,\n",
      "       0.91540515], dtype=float32)\n",
      "One row of metrics: {'AUC': 'Not Defined',\n",
      " 'Accuracy': 'Not Defined',\n",
      " 'F1': 'Not Defined',\n",
      " 'FN': 135,\n",
      " 'FP': 0,\n",
      " 'Label': 'adopted',\n",
      " 'NPV': 'Not Defined',\n",
      " 'PPV': 'Not Defined',\n",
      " 'Prevalence': 'Not Defined',\n",
      " 'Sensitivity': 'Not Defined',\n",
      " 'Specificity': 'Not Defined',\n",
      " 'TN': 0,\n",
      " 'TP': 1528,\n",
      " 'Threshold': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Prevalence</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not adopted</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adopted</td>\n",
       "      <td>1528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>Not Defined</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label    TP   TN   FP   FN     Accuracy   Prevalence  Sensitivity  \\\n",
       "0  not adopted     0  197  448    0  Not Defined  Not Defined  Not Defined   \n",
       "1      adopted  1528    0    0  135  Not Defined  Not Defined  Not Defined   \n",
       "\n",
       "   Specificity          PPV          NPV          AUC           F1  Threshold  \n",
       "0  Not Defined  Not Defined  Not Defined  Not Defined  Not Defined        0.5  \n",
       "1  Not Defined  Not Defined  Not Defined  Not Defined  Not Defined        0.5  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_array = np.array(y_true)\n",
    "y_pred_sorted_array = np.array(y_pred_sorted)\n",
    "tf.print(\"y_true_array:\", y_true_array)\n",
    "tf.print(\"len class_labels:\", len(class_labels))\n",
    "metrics = get_performance_metrics(y_true_array, y_pred_sorted_array, class_labels)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(metrics[\"TP\"], tpr_keras, label='ROC'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#visualize model in an interactive way\n",
    "#sadly only works until the preprocessing layers are over\n",
    "# tensorboard sometimes thinks there still is an instance running when it is not\n",
    "# fix that by deleting the contents of this folder or your equivalent of it\n",
    "# C:\\Users\\deisl\\AppData\\Local\\Temp\\.tensorboard-info\n",
    "\n",
    "%reload_ext tensorboard\n",
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZMnTKaCZda"
   },
   "source": [
    "## Inference on new data\n",
    "\n",
    "As the model contains all important parts, it should be able to work on any file of the right format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xkOlK8Zweeh"
   },
   "source": [
    "The model should be saved such that it can just be reloaded later.\\\n",
    "I will follow the tutorial [here](https://www.tensorflow.org/tutorials/keras/save_and_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.296839Z",
     "iopub.status.busy": "2020-09-17T01:33:52.296192Z",
     "iopub.status.idle": "2020-09-17T01:33:56.352943Z",
     "shell.execute_reply": "2020-09-17T01:33:56.352275Z"
    },
    "id": "QH9Zy1sBvwOH",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "functional_model.save('my_pet_classifier')\n",
    "reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D973plJrdwQ9"
   },
   "source": [
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are just two things you need to do:\n",
    "\n",
    "1.   Wrap scalars into a list so as to have a batch dimension (models only process batches of data, not single samples)\n",
    "2.   Call `convert_to_tensor` on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:56.360094Z",
     "iopub.status.busy": "2020-09-17T01:33:56.359400Z",
     "iopub.status.idle": "2020-09-17T01:33:56.669531Z",
     "shell.execute_reply": "2020-09-17T01:33:56.669015Z"
    },
    "id": "rKq4pxtdDa7i",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO this does not work\n",
    "\n",
    "sample = {\n",
    "    'Type': 'Cat',\n",
    "    'Age': 3,\n",
    "    'Breed1': 'Tabby',\n",
    "    'Gender': 'Male',\n",
    "    'Color1': 'Black',\n",
    "    'Color2': 'White',\n",
    "    'MaturitySize': 'Small',\n",
    "    'FurLength': 'Short',\n",
    "    'Vaccinated': 'No',\n",
    "    'Sterilized': 'No',\n",
    "    'Health': 'Healthy',\n",
    "    'Fee': 100,\n",
    "    'PhotoAmt': 2,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "\n",
    "prediction_example = preprocesessing_model(sample)\n",
    "\n",
    "\n",
    "predictions = functional_model.predict(prediction_example)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "Old code for reference:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing_layers.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}