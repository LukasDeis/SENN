{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg02FZzDyEqd"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.289130Z",
     "iopub.status.busy": "2020-09-17T01:33:34.288557Z",
     "iopub.status.idle": "2020-09-17T01:33:34.290255Z",
     "shell.execute_reply": "2020-09-17T01:33:34.290746Z"
    },
    "id": "2mapZ9afGJ69"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- fix model creation (preprocessing breaks tensor? https://tensorflow.google.cn/tutorials/load_data/csv)\n",
    "\n",
    "- name all layers\n",
    "\n",
    "- save model for loading afterwards (currently broken, might require named layers, might clash with concatenate layer)\n",
    "\n",
    "- make sure to mark unaltered cells and annotations as from the original tutorial\n",
    "\n",
    "- make sure the GPU is used\n",
    "\n",
    "- make model .fit and .evaluate work (if it does not)\n",
    "\n",
    "- make callbacks work during fitting (in custom loop)\n",
    "\n",
    "\n",
    "Maybe:\n",
    "\n",
    "- make a preprocessing model where the preprocessing is done when SENN is initialized\n",
    "(for portability)\n",
    "\n",
    "- augment data by just adding random noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMYQvJuBi7MS"
   },
   "source": [
    "# Classify structured data using Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FaL4wnr22oy"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/preprocessing_layers.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/preprocessing_layers.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nna1tOKxyEqe"
   },
   "source": [
    "This tutorial demonstrates how to classify structured data (e.g. tabular data in a CSV). You will use [Keras](https://www.tensorflow.org/guide/keras) to define the model, and [preprocessing layers](https://keras.io/guides/preprocessing_layers/) as a bridge to map from columns in a CSV to features used to train the model. This tutorial contains complete code to:\n",
    "\n",
    "* Load a CSV file using [Pandas](https://pandas.pydata.org/).\n",
    "* Build an input pipeline to batch and shuffle the rows using [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "* Map from columns in the CSV to features used to train the model using Keras Preprocessing layers.\n",
    "* Build, train, and evaluate a model using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5xkXCicjFQD"
   },
   "source": [
    "Note: This tutorial is similar to [Classify structured data with feature columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns). This version uses new experimental Keras [Preprocessing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing) instead of `tf.feature_column`. Keras Preprocessing Layers are more intuitive, and can be easily included inside your model to simplify deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHxU1FMNpomc"
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "For designing the network I use a smaller and simpler dataset. \n",
    "\n",
    "It is a simplified version of the PetFinder [dataset](https://www.kaggle.com/c/petfinder-adoption-prediction). There are several thousand rows in the CSV. Each row describes a pet, and each column describes an attribute. \n",
    "\n",
    "The goal is to predict if the pet will be adopted.\n",
    "\n",
    "Following is a description of this dataset. \\\n",
    "Notice there are both numeric and categorical columns. \n",
    "\n",
    "The free text column will be ignored.\n",
    "\n",
    "Column | Description| Feature Type | Data Type\n",
    "------------|--------------------|----------------------|-----------------\n",
    "Type | Type of animal (Dog, Cat) | Categorical | string\n",
    "Age |  Age of the pet | Numerical | integer\n",
    "Breed1 | Primary breed of the pet | Categorical | string\n",
    "Color1 | Color 1 of pet | Categorical | string\n",
    "Color2 | Color 2 of pet | Categorical | string\n",
    "MaturitySize | Size at maturity | Categorical | string\n",
    "FurLength | Fur length | Categorical | string\n",
    "Vaccinated | Pet has been vaccinated | Categorical | string\n",
    "Sterilized | Pet has been sterilized | Categorical | string\n",
    "Health | Health Condition | Categorical | string\n",
    "Fee | Adoption Fee | Numerical | integer\n",
    "Description | Profile write-up for this pet | Text | string\n",
    "PhotoAmt | Total uploaded photos for this pet | Numerical | integer\n",
    "AdoptionSpeed | Speed of adoption | Classification | integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjFbdBldyEqf"
   },
   "source": [
    "## Install and Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.295537Z",
     "iopub.status.busy": "2020-09-17T01:33:34.294862Z",
     "iopub.status.idle": "2020-09-17T01:33:35.675952Z",
     "shell.execute_reply": "2020-09-17T01:33:35.675219Z"
    },
    "id": "S_BdyQlPjfDW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: pydot in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from pydotplus) (2.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (0.14.2)\n",
      "Requirement already satisfied: datetime in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (4.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from datetime) (2020.4)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from datetime) (5.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from zope.interface->datetime) (50.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from packaging) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from packaging) (1.15.0)\n",
      "Requirement already satisfied: keras in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: six in c:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz\n",
    "!pip install datetime\n",
    "!pip install packaging\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install for graph: https://graphviz.gitlab.io/download/\n",
    "maybe follow: https://bobswift.atlassian.net/wiki/spaces/GVIZ/pages/131924165/Graphviz+installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from datetime import datetime\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXvBvobayEqi"
   },
   "source": [
    "## Reading in the data\n",
    "\n",
    "The data is read into a pandas dataframe\n",
    "\n",
    "Again:\\\n",
    "As the real data is sensitive, large and expensive to use,\n",
    "for now I use a dummy dataset about adoption-speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.197790Z",
     "iopub.status.busy": "2020-09-17T01:33:42.197028Z",
     "iopub.status.idle": "2020-09-17T01:33:42.321623Z",
     "shell.execute_reply": "2020-09-17T01:33:42.320979Z"
    },
    "id": "qJ4Ajn-YyEqj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
    "                        extract=True, cache_dir='.')\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.343796Z",
     "iopub.status.busy": "2020-09-17T01:33:42.343010Z",
     "iopub.status.idle": "2020-09-17T01:33:42.352803Z",
     "shell.execute_reply": "2020-09-17T01:33:42.353374Z"
    },
    "id": "3uiq4hoIGyXI",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  \\\n",
       "0     Short         No         No  Healthy  100   \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0   \n",
       "2    Medium        Yes         No  Healthy    0   \n",
       "3     Short        Yes         No  Healthy  150   \n",
       "4     Short         No         No  Healthy    0   \n",
       "\n",
       "                                         Description  PhotoAmt  AdoptionSpeed  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...         1              2  \n",
       "1  I just found it alone yesterday near my apartm...         2              0  \n",
       "2  Their pregnant mother was dumped by her irresp...         7              3  \n",
       "3  Good guard dog, very alert, active, obedience ...         8              2  \n",
       "4  This handsome yet cute boy is up for adoption....         3              2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3zDbrozyEqq"
   },
   "source": [
    "## Creating the target variable\n",
    "\n",
    "I have to select the variable I want to train for and drop the columns that are not important or contain that information from the normal dataset.\n",
    "\n",
    "Valid for the example data:\n",
    "The task in the Kaggle competition was to predict the speed at which a pet will be adopted (e.g., in the first week, the first month, the first three months, and so on). Let's simplify this for our purposes. It is transformed into a binary classification problem:\n",
    "I simply predict whether the pet was adopted, or not.\n",
    "\n",
    "After modifying the label column, 0 will indicate the pet was not adopted, and 1 will indicate it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.358975Z",
     "iopub.status.busy": "2020-09-17T01:33:42.358305Z",
     "iopub.status.idle": "2020-09-17T01:33:42.365151Z",
     "shell.execute_reply": "2020-09-17T01:33:42.364619Z"
    },
    "id": "wmMDc46-yEqq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop un-used columns. (including our now target which can not be used for training)\n",
    "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataframe = dataframe.drop(columns=['Fee', 'PhotoAmt','Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "#                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1'])\n",
    "\n",
    "#for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  PhotoAmt  target  \n",
       "0     Short         No         No  Healthy  100         1       1  \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0         2       1  \n",
       "2    Medium        Yes         No  Healthy    0         7       1  \n",
       "3     Short        Yes         No  Healthy  150         8       1  \n",
       "4     Short         No         No  Healthy    0         3       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp0NCbswyEqs"
   },
   "source": [
    "## Spliting the dataframe into train, validation, and test\n",
    "\n",
    "The loaded dataset was a single file. It has to be split into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.370622Z",
     "iopub.status.busy": "2020-09-17T01:33:42.369987Z",
     "iopub.status.idle": "2020-09-17T01:33:42.377950Z",
     "shell.execute_reply": "2020-09-17T01:33:42.378325Z"
    },
    "id": "qT6HdyEwyEqt",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7383 train examples\n",
      "1846 validation examples\n",
      "2308 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_7uVu-xyEqv"
   },
   "source": [
    "## Input pipeline\n",
    "\n",
    "The dataframe is wrapped with [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "This is done to easily shuffle and batch the data. \n",
    "\n",
    "If the RAM is not sufficient, tf.data could be used directly to read it from disk in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.383853Z",
     "iopub.status.busy": "2020-09-17T01:33:42.383254Z",
     "iopub.status.idle": "2020-09-17T01:33:42.385369Z",
     "shell.execute_reply": "2020-09-17T01:33:42.384906Z"
    },
    "id": "7r4j-1lRyEqw",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=1):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYxIXH579uS9"
   },
   "source": [
    "The general pipeline for input is finished here.\n",
    "What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.803710Z",
     "iopub.status.busy": "2020-09-17T01:33:42.388965Z",
     "iopub.status.idle": "2020-09-17T01:33:43.830128Z",
     "shell.execute_reply": "2020-09-17T01:33:43.830540Z"
    },
    "id": "tYiNH-QI96Jo",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.836836Z",
     "iopub.status.busy": "2020-09-17T01:33:43.836165Z",
     "iopub.status.idle": "2020-09-17T01:33:43.891242Z",
     "shell.execute_reply": "2020-09-17T01:33:43.890630Z"
    },
    "id": "nFYir6S8HgIJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n",
      "A batch of ages: tf.Tensor([ 4 50 24 17  3], shape=(5,), dtype=int64)\n",
      "A batch of targets: tf.Tensor([0 0 1 1 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['Age'])\n",
    "print('A batch of targets:', label_batch )\n",
    "\n",
    "# TODO currently this is targeted towards the dummy -set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geqHWW54Hmte"
   },
   "source": [
    "The dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v50jBIuj4gb"
   },
   "source": [
    "## Preprocessing layers\n",
    "\n",
    "I will have to adapt the pipelines when I replace the dummy-code, but afterwards I will be able to input plain string data etc from new data as well.\n",
    "\n",
    "Information about the pre-processing layers for easy access when I am there:\n",
    "\n",
    "*   [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) - Feature-wise normalization of the data.\n",
    "*   [`CategoryEncoding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryEncoding) - Category encoding layer.\n",
    "*   [`StringLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup) - Maps strings from a vocabulary to integer indices.\n",
    "*   [`IntegerLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup) - Maps integers from a vocabulary to integer indices.\n",
    "\n",
    "A list of available preprocessing layers can be found [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twXBSxnT66o8"
   },
   "source": [
    "### Numeric columns\n",
    "A Normalization() layer ensures that each numeric feature has a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OosUh4kTsK_q"
   },
   "source": [
    "The `get_normalization_layer` function returns a keras layer.\n",
    "It applies featurewise normalization to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.896825Z",
     "iopub.status.busy": "2020-09-17T01:33:43.896137Z",
     "iopub.status.idle": "2020-09-17T01:33:43.898143Z",
     "shell.execute_reply": "2020-09-17T01:33:43.898564Z"
    },
    "id": "D6OuEKMMyEq1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization()\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.903065Z",
     "iopub.status.busy": "2020-09-17T01:33:43.902172Z",
     "iopub.status.idle": "2020-09-17T01:33:44.842415Z",
     "shell.execute_reply": "2020-09-17T01:33:44.842862Z"
    },
    "id": "MpKgUDyk69bM",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[-0.50468034],\n",
       "       [ 0.14564772],\n",
       "       [-0.17951629],\n",
       "       [-0.50468034],\n",
       "       [-0.17951629]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_count_col = train_features['PhotoAmt']\n",
    "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
    "layer(photo_count_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWY00YBUx9N"
   },
   "source": [
    "TODO: If I will indeed have many numeric features (hundreds, or more), it would be more efficient to concatenate them first and use a single [normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVD--2WZ7vmh"
   },
   "source": [
    "### Categorical columns\n",
    "\n",
    "In the dummy dataset, Type is represented as a string (e.g. 'Dog', or 'Cat'). Sadly, one can not feed strings directly to a model. The preprocessing layer takes care of representing strings as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWlkOPwMsxdv"
   },
   "source": [
    "The `get_category_encoding_layer` function returns a layer, mapping values from a vocabulary to integer indices and one-hot encodes the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:44.850381Z",
     "iopub.status.busy": "2020-09-17T01:33:44.847119Z",
     "iopub.status.idle": "2020-09-17T01:33:44.851920Z",
     "shell.execute_reply": "2020-09-17T01:33:44.852447Z"
    },
    "id": "GmgaeRjlDoUO",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_values=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = feature_ds.map(index)\n",
    "\n",
    "  # Learn the space of possible indices.\n",
    "  encoder.adapt(feature_ds)\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:44.862532Z",
     "iopub.status.busy": "2020-09-17T01:33:44.861894Z",
     "iopub.status.idle": "2020-09-17T01:33:45.538315Z",
     "shell.execute_reply": "2020-09-17T01:33:45.537801Z"
    },
    "id": "X2t2ff9K8PcT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Type']\n",
    "layer = get_category_encoding_layer('Type', train_ds, 'string')\n",
    "layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6eDongw8knz"
   },
   "source": [
    "Often, you don't want to feed a number directly into the model, but instead use a one-hot encoding of those inputs. Consider raw data that represents a pet's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:45.546513Z",
     "iopub.status.busy": "2020-09-17T01:33:45.545857Z",
     "iopub.status.idle": "2020-09-17T01:33:46.118888Z",
     "shell.execute_reply": "2020-09-17T01:33:46.118367Z"
    },
    "id": "7FjBioQ38oNE",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Age']\n",
    "category_encoding_layer = get_category_encoding_layer('Age', train_ds,\n",
    "                                                      'int64', 5)\n",
    "category_encoding_layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiE0glOPkMyh"
   },
   "source": [
    "## Choosing and preparing columns to use\n",
    "\n",
    "While we can deal with all types of data, we have to make a list of all columns for each type.\\\n",
    "That way I am able to define which layer needs to be treated how\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.142976Z",
     "iopub.status.busy": "2020-09-17T01:33:46.123925Z",
     "iopub.status.idle": "2020-09-17T01:33:46.180021Z",
     "shell.execute_reply": "2020-09-17T01:33:46.180497Z"
    },
    "id": "Rcv2kQTTo23h",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.190642Z",
     "iopub.status.busy": "2020-09-17T01:33:46.186870Z",
     "iopub.status.idle": "2020-09-17T01:33:46.368301Z",
     "shell.execute_reply": "2020-09-17T01:33:46.368852Z"
    },
    "id": "Q3RBa51VkaAn",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['PhotoAmt', 'Fee']:  # TODO use all headers in UMC set minus the ones I know are something else\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.379746Z",
     "iopub.status.busy": "2020-09-17T01:33:46.378953Z",
     "iopub.status.idle": "2020-09-17T01:33:46.551415Z",
     "shell.execute_reply": "2020-09-17T01:33:46.550766Z"
    },
    "id": "1FOMGfZflhoA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers.\n",
    "\n",
    "# TODO at the UMC data, this will be more common, some tests have a categorical scale \n",
    "# However, most of them can just be interpreted as normal numerical feature, so I won't have to overdo it\n",
    "age_col = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
    "encoding_layer = get_category_encoding_layer('Age', train_ds, dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.561248Z",
     "iopub.status.busy": "2020-09-17T01:33:46.560569Z",
     "iopub.status.idle": "2020-09-17T01:33:48.254306Z",
     "shell.execute_reply": "2020-09-17T01:33:48.254765Z"
    },
    "id": "K8C8xyiXm-Ie",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "categorical_cols = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1'] \n",
    "# TODO replace this by reading the headings from the dataframe and substracting the hardcoded headings (that I know are something else))\n",
    "\n",
    "for header in categorical_cols:\n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5) # TODO maybe, this line has to be duplicated and slightly changed to accomodate for different max_tokens\n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Currently I do not think the UMC data needs to be balanced.\n",
    "# It will be evaluated on the same dataset (though a different part of it)\n",
    "# We do not have a large number of samples that are underrepresented, probably causing large inaccura\n",
    "\n",
    "#use:\n",
    "#    https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHSnhz2fyEq3"
   },
   "source": [
    "## The model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Color1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Color2 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "MaturitySize (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FurLength (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Vaccinated (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Sterilized (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Health (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PhotoAmt (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Fee (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "integer_lookup_1 (IntegerLookup (None, 1)            0           Age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_1 (StringLookup)  (None, 1)            0           Type[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_2 (StringLookup)  (None, 1)            0           Color1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_3 (StringLookup)  (None, 1)            0           Color2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_4 (StringLookup)  (None, 1)            0           Gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_5 (StringLookup)  (None, 1)            0           MaturitySize[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_6 (StringLookup)  (None, 1)            0           FurLength[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_7 (StringLookup)  (None, 1)            0           Vaccinated[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_8 (StringLookup)  (None, 1)            0           Sterilized[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_9 (StringLookup)  (None, 1)            0           Health[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_10 (StringLookup) (None, 1)            0           Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 1)            3           PhotoAmt[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "normalization_2 (Normalization) (None, 1)            3           Fee[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_2 (CategoryEn (None, 5)            0           integer_lookup_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_3 (CategoryEn (None, 4)            0           string_lookup_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_4 (CategoryEn (None, 5)            0           string_lookup_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_5 (CategoryEn (None, 5)            0           string_lookup_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_6 (CategoryEn (None, 4)            0           string_lookup_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_7 (CategoryEn (None, 5)            0           string_lookup_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_8 (CategoryEn (None, 5)            0           string_lookup_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_9 (CategoryEn (None, 5)            0           string_lookup_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_10 (CategoryE (None, 5)            0           string_lookup_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_11 (CategoryE (None, 5)            0           string_lookup_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_12 (CategoryE (None, 5)            0           string_lookup_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 55)           0           normalization_1[0][0]            \n",
      "                                                                 normalization_2[0][0]            \n",
      "                                                                 category_encoding_2[0][0]        \n",
      "                                                                 category_encoding_3[0][0]        \n",
      "                                                                 category_encoding_4[0][0]        \n",
      "                                                                 category_encoding_5[0][0]        \n",
      "                                                                 category_encoding_6[0][0]        \n",
      "                                                                 category_encoding_7[0][0]        \n",
      "                                                                 category_encoding_8[0][0]        \n",
      "                                                                 category_encoding_9[0][0]        \n",
      "                                                                 category_encoding_10[0][0]       \n",
      "                                                                 category_encoding_11[0][0]       \n",
      "                                                                 category_encoding_12[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 6\n",
      "Trainable params: 0\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The first step towards a working model\n",
    "# is our preprocessed input.\n",
    "# As that is a relative complex task, that is regarded it's owy model.\n",
    "\n",
    "preprocessed_layers = layers.Concatenate()(encoded_features) #encoded_features\n",
    "preprocesessing_model = tf.keras.Model(all_inputs, preprocessed_layers)\n",
    "preprocesessing_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the models structure, there are repetetive patterns.\n",
    "\n",
    "For readability those layers are combined into custom layers and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# A combination of layers, common in the parameterizer\n",
    "\n",
    "class ParameterizerLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, out_shape, dropout_rate):\n",
    "        super(ParameterizerLayer, self).__init__()\n",
    "        self.para_lin = layers.Dense(out_shape, activation='linear')\n",
    "        self.para_drop = layers.Dropout(dropout_rate)\n",
    "        self.para_relu = layers.Dense(out_shape, activation=tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "        \n",
    "    \n",
    "    def call(self, input_tensor,  training=False):\n",
    "        x = self.para_lin(input_tensor)\n",
    "        if training:\n",
    "            x = self.para_drop(x, training=training)\n",
    "        x = self.para_relu(x)        \n",
    "        return x\n",
    "    \n",
    "# should minimize robustness loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functional model def\n",
    "\n",
    "#TODO no more static sizes\n",
    "batch_size = 1\n",
    "preprocessed_inputs_shape = 55 \n",
    "dropout_rate=0.1\n",
    "hidden_sizes = [40, 20, 15, 5]  # TODO fix this to actual size\n",
    "out_shape = preprocessed_inputs_shape\n",
    "\n",
    "input_shape = [batch_size, preprocessed_inputs_shape]\n",
    "input_layer = layers.Input(batch_shape = input_shape)\n",
    "\n",
    "x = input_layer\n",
    "###Parameterizer###\n",
    "x = ParameterizerLayer(hidden_sizes[0], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[1], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[2], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[3], dropout_rate)(x)\n",
    "x = layers.Dense(out_shape, activation='linear')(x)\n",
    "relevances = layers.Dropout(rate=dropout_rate, name=\"relevances\")(x)\n",
    "\n",
    "###Conceptizer###\n",
    "concepts = layers.Lambda(lambda t: t, name=\"concepts\")(input_layer)\n",
    "\n",
    "###Aggregator###\n",
    "\n",
    "aggregated = layers.multiply([relevances, concepts])\n",
    "aggregated = layers.Lambda(lambda t: tf.keras.backend.sum(t, axis=-1))(aggregated)\n",
    "aggregated = layers.Lambda(lambda t: tf.keras.activations.sigmoid(t), name=\"output\")(aggregated)\n",
    "\n",
    "out_layer = [aggregated, concepts, relevances]\n",
    "\n",
    "functional_model = tf.keras.Model(inputs=input_layer, outputs=out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom fun with more inputs\n",
    "\n",
    "def get_custom_loss(some_other_argument):\n",
    "    \n",
    "    def custom_loss(y_true, y_pred): \n",
    "        loss = 0\n",
    "        loss = loss + some_other_argument\n",
    "        loss = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        return loss\n",
    "    \n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_loss(y_true, y_pred):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(1, 55)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_28 (Paramet (1, 40)              3880        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_29 (Paramet (1, 20)              1240        parameterizer_layer_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_30 (Paramet (1, 15)              555         parameterizer_layer_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_31 (Paramet (1, 5)               110         parameterizer_layer_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (1, 55)              330         parameterizer_layer_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "relevances (Dropout)            (1, 55)              0           dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concepts (Lambda)               (1, 55)              0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (1, 55)              0           relevances[0][0]                 \n",
      "                                                                 concepts[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (1,)                 0           multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (1,)                 0           lambda_7[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,115\n",
      "Trainable params: 6,115\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_dict = {\n",
    "    \"relevances\": keras.losses.mean_absolute_error, #get_custom_loss(some_other_argument=1),\n",
    "    \"output\": keras.losses.binary_crossentropy, #tf.nn.log_poisson_loss,\n",
    "    \"concepts\": zero_loss\n",
    "}\n",
    "\n",
    "functional_model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=loss_dict,\n",
    "    loss_weights=[1, 5, 0],\n",
    "    metrics= ['accuracy']\n",
    ")  \n",
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do pre-processing of data separately\n",
    "processed_train_ds = train_ds.map(\n",
    "  lambda x, y: (\n",
    "      tf.cast(preprocesessing_model(x), dtype=tf.float32), \n",
    "      tf.cast(y, dtype=tf.float32)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:48.331722Z",
     "iopub.status.busy": "2020-09-17T01:33:48.330973Z",
     "iopub.status.idle": "2020-09-17T01:33:48.644924Z",
     "shell.execute_reply": "2020-09-17T01:33:48.645441Z"
    },
    "id": "Y7Bkx4c7yEq5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback, used for the animated, interactive tensorboard visualizatioon\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "#This should plot the exhaustive graph, but is a bit unreliable\n",
    "tf.keras.utils.plot_model(functional_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ParameterizerLayer has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/10\n",
      "   2/7383 [..............................] - ETA: 34:53 - loss: 0.2899 - output_loss: 0.2899 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5773 - output_accuracy: 1.0000 - concepts_accuracy: 0.5000 - relevances_accuracy: 0.0000e+00 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.5663s). Check your callbacks.\n",
      "7383/7383 [==============================] - 8s 1ms/step - loss: 0.5111 - output_loss: 0.5111 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5822 - output_accuracy: 0.7516 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7383/7383 [==============================] - 7s 965us/step - loss: 0.5003 - output_loss: 0.5003 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5669 - output_accuracy: 0.7548 - concepts_accuracy: 0.0642 - relevances_accuracy: 1.3545e-04\n",
      "Epoch 3/10\n",
      "7383/7383 [==============================] - 6s 877us/step - loss: 0.5016 - output_loss: 0.5016 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5817 - output_accuracy: 0.7576 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7383/7383 [==============================] - 6s 823us/step - loss: 0.5047 - output_loss: 0.5047 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5729 - output_accuracy: 0.7535 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "7383/7383 [==============================] - 7s 899us/step - loss: 0.5060 - output_loss: 0.5060 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5833 - output_accuracy: 0.7466 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "7383/7383 [==============================] - 6s 865us/step - loss: 0.5023 - output_loss: 0.5023 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5945 - output_accuracy: 0.7552 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "7383/7383 [==============================] - 6s 828us/step - loss: 0.5071 - output_loss: 0.5071 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5836 - output_accuracy: 0.7539 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "7383/7383 [==============================] - 6s 802us/step - loss: 0.5052 - output_loss: 0.5052 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5721 - output_accuracy: 0.7506 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "7383/7383 [==============================] - 6s 789us/step - loss: 0.5047 - output_loss: 0.5047 - concepts_loss: 0.0000e+00 - relevances_loss: 0.6364 - output_accuracy: 0.7540 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "7383/7383 [==============================] - 6s 824us/step - loss: 0.5033 - output_loss: 0.5033 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5848 - output_accuracy: 0.7580 - concepts_accuracy: 0.0642 - relevances_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bec2d8c10>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.print(\"processed_train_ds shape:\", processed_train_ds.take(0))\n",
    "functional_model.fit(processed_train_ds, epochs=10, callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\\\n",
    "1: The error refers to this:\\\n",
    "I provide a gradient for every input feature (55),\\\n",
    "    that makes sense as my parameterizer has output-dimensions of one per input.\\\n",
    "However, it wants a second dimension of 10,\\\n",
    "    which is de dimension of the FIRST layer of the parameterizer, NOT the last.\\\n",
    "I do not understand that or what to do about it.\\\n",
    "\\\n",
    "2: How can I constrain the output to something from 0 to 1 without disconnecting the graph?\\\n",
    "3: Why are there only 18 trainable weights when the model has 55 preprocessed inputs\\\n",
    "   and the parameterizer has more than 18 outputs?\\\n",
    "4: How do I scale up to a larger batch_size, given that now I have to use the [0] trick to make it work?\\\n",
    "5: Why is the classification loss so weird sometimes target = predicted should give 0, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6mNMfG6yEq5"
   },
   "source": [
    "Let's visualize our connectivity graph:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pre-processing of data separately\n",
    "processed_test_ds = test_ds.map(\n",
    "  lambda x, y: (\n",
    "      tf.cast(preprocesessing_model(x), dtype=tf.float32), \n",
    "      tf.cast(y, dtype=tf.float32)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.231471Z",
     "iopub.status.busy": "2020-09-17T01:33:52.230837Z",
     "iopub.status.idle": "2020-09-17T01:33:52.288853Z",
     "shell.execute_reply": "2020-09-17T01:33:52.289388Z"
    },
    "id": "T8N2uAdU2Cni",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2308/2308 [==============================] - 1s 534us/step - loss: 0.5043 - output_loss: 0.5043 - concepts_loss: 0.0000e+00 - relevances_loss: 0.5528 - output_accuracy: 0.7595 - concepts_accuracy: 0.0602 - relevances_accuracy: 0.0000e+00\n",
      "Accuracy [0.5042999386787415, 0.5042999386787415, 0.0, 0.5528015494346619, 0.7595320343971252, 0.06022530421614647, 0.0]\n"
     ]
    }
   ],
   "source": [
    "accuracy = functional_model.evaluate(processed_test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide x and y of test set\n",
    "x = []\n",
    "y_true = []\n",
    "\n",
    "for x_var, y_var in processed_test_ds:\n",
    "    x.append(x_var)\n",
    "    y_true.append(y_var[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### coursera util.py for metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "\n",
    "def get_true_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 1))\n",
    "\n",
    "\n",
    "def get_true_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 0))\n",
    "\n",
    "\n",
    "def get_false_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 1))\n",
    "\n",
    "\n",
    "def get_false_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 0))\n",
    "\n",
    "\n",
    "def get_performance_metrics(y, pred, class_labels, tp=get_true_pos,\n",
    "                            tn=get_true_neg, fp=get_false_pos,\n",
    "                            fn=get_false_neg,\n",
    "                            acc=None, prevalence=None, spec=None,\n",
    "                            sens=None, ppv=None, npv=None, auc=None, f1=None,\n",
    "                            thresholds=[]):\n",
    "    if len(thresholds) != len(class_labels):\n",
    "        thresholds = [.5] * len(class_labels)\n",
    "\n",
    "    columns = [\"\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"Prevalence\",\n",
    "               \"Sensitivity\",\n",
    "               \"Specificity\", \"PPV\", \"NPV\", \"AUC\", \"F1\", \"Threshold\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in range(len(class_labels)):\n",
    "        df.loc[i] = [\"\"] + [0] * (len(columns) - 1)\n",
    "        df.loc[i][0] = class_labels[i]\n",
    "        df.loc[i][1] = round(tp(y[:, i], pred[:, i]),\n",
    "                             3) if tp != None else \"Not Defined\"\n",
    "        df.loc[i][2] = round(tn(y[:, i], pred[:, i]),\n",
    "                             3) if tn != None else \"Not Defined\"\n",
    "        df.loc[i][3] = round(fp(y[:, i], pred[:, i]),\n",
    "                             3) if fp != None else \"Not Defined\"\n",
    "        df.loc[i][4] = round(fn(y[:, i], pred[:, i]),\n",
    "                             3) if fn != None else \"Not Defined\"\n",
    "        df.loc[i][5] = round(acc(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if acc != None else \"Not Defined\"\n",
    "        df.loc[i][6] = round(prevalence(y[:, i]),\n",
    "                             3) if prevalence != None else \"Not Defined\"\n",
    "        df.loc[i][7] = round(sens(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if sens != None else \"Not Defined\"\n",
    "        df.loc[i][8] = round(spec(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if spec != None else \"Not Defined\"\n",
    "        df.loc[i][9] = round(ppv(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if ppv != None else \"Not Defined\"\n",
    "        df.loc[i][10] = round(npv(y[:, i], pred[:, i], thresholds[i]),\n",
    "                              3) if npv != None else \"Not Defined\"\n",
    "        df.loc[i][11] = round(auc(y[:, i], pred[:, i]),\n",
    "                              3) if auc != None else \"Not Defined\"\n",
    "        df.loc[i][12] = round(f1(y[:, i], pred[:, i] > thresholds[i]),\n",
    "                              3) if f1 != None else \"Not Defined\"\n",
    "        df.loc[i][13] = round(thresholds[i], 3)\n",
    "\n",
    "    df = df.set_index(\"\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_confidence_intervals(class_labels, statistics):\n",
    "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
    "    for i in range(len(class_labels)):\n",
    "        mean = statistics.mean(axis=1)[i]\n",
    "        max_ = np.quantile(statistics, .95, axis=1)[i]\n",
    "        min_ = np.quantile(statistics, .05, axis=1)[i]\n",
    "        df.loc[class_labels[i]] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_curve(gt, pred, target_names, curve='roc'):\n",
    "    for i in range(len(target_names)):\n",
    "        if curve == 'roc':\n",
    "            curve_function = roc_curve\n",
    "            auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" AUC: %.3f \" % auc_roc\n",
    "            xlabel = \"False positive rate\"\n",
    "            ylabel = \"True positive rate\"\n",
    "            a, b, _ = curve_function(gt[:, i], pred[:, i])\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.plot(a, b, label=label)\n",
    "            plt.xlabel(xlabel)\n",
    "            plt.ylabel(ylabel)\n",
    "\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n",
    "        elif curve == 'prc':\n",
    "            precision, recall, _ = precision_recall_curve(gt[:, i], pred[:, i])\n",
    "            average_precision = average_precision_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" Avg.: %.3f \" % average_precision\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.step(recall, precision, where='post', label=label)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.83355117], dtype=float32),\n",
      " array([[-0.17951629, -0.29800498,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "         1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ]],\n",
      "      dtype=float32),\n",
      " array([[ 0.16350377, -0.14218885,  0.84711605, -0.2071761 ,  0.365334  ,\n",
      "         0.21852273,  0.822676  ,  0.954883  ,  0.9507357 ,  0.10321509,\n",
      "        -0.03831842,  0.9494834 ,  0.19175689,  0.09590086,  0.12811491,\n",
      "         0.17690666,  0.9537591 ,  0.11173366,  0.0610581 ,  0.1216288 ,\n",
      "         0.1468724 ,  0.95177376,  0.95080996,  0.02868536,  0.11298294,\n",
      "         0.9455952 ,  0.95220673,  0.10522979,  0.01481123,  0.18495259,\n",
      "         0.9545461 ,  0.9537144 ,  0.0166777 ,  0.10107262,  0.29611412,\n",
      "         0.9509097 ,  0.95168984,  0.0740577 ,  0.0164935 ,  0.04708032,\n",
      "         0.951923  ,  0.9486133 ,  0.3174726 , -0.0877582 , -0.11695215,\n",
      "         0.95019984,  0.95235884,  0.04862886, -0.03021611,  0.51390785,\n",
      "         0.9512755 ,  0.47293103, -0.16736381,  0.20216234,  0.15332885]],\n",
      "      dtype=float32)]\r\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-382-55c05f701b50>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m### binarize the classifications\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mthreshold\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0my_pred_binary\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"y_pred_binary:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred_binary\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '>' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred = functional_model.predict(x)[0]\n",
    "### binarize the classifications\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "tf.print(\"y_pred_binary:\", y_pred_binary)\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_labels = ['not adopted', 'adopted']\n",
    "get_curve(y, y_pred, class_labels, curve='roc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='ROC'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-377-20e3c2607664>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mclass_labels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'not adopted'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'adopted'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mget_curve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred_binary\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcurve\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'roc'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-365-ebf7a72c526a>\u001B[0m in \u001B[0;36mget_curve\u001B[1;34m(gt, pred, target_names, curve)\u001B[0m\n\u001B[0;32m     92\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcurve\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'roc'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m             \u001B[0mcurve_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mroc_curve\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 94\u001B[1;33m             \u001B[0mauc_roc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mroc_auc_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgt\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpred\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m             \u001B[0mlabel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtarget_names\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\" AUC: %.3f \"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mauc_roc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m             \u001B[0mxlabel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"False positive rate\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36m_slice_helper\u001B[1;34m(tensor, slice_spec, var)\u001B[0m\n\u001B[0;32m   1011\u001B[0m       \u001B[0mvar_empty\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1012\u001B[0m       \u001B[0mpacked_begin\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpacked_end\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpacked_strides\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvar_empty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1013\u001B[1;33m     return strided_slice(\n\u001B[0m\u001B[0;32m   1014\u001B[0m         \u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1015\u001B[0m         \u001B[0mpacked_begin\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mstrided_slice\u001B[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001B[0m\n\u001B[0;32m   1184\u001B[0m     \u001B[0mstrides\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mones_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbegin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1185\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1186\u001B[1;33m   op = gen_array_ops.strided_slice(\n\u001B[0m\u001B[0;32m   1187\u001B[0m       \u001B[0minput\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1188\u001B[0m       \u001B[0mbegin\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbegin\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001B[0m in \u001B[0;36mstrided_slice\u001B[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001B[0m\n\u001B[0;32m  10318\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m  10319\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m> 10320\u001B[1;33m       \u001B[0m_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m  10321\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m  10322\u001B[0m       \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   6841\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m\" name: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;34m\"\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6842\u001B[0m   \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6843\u001B[1;33m   \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   6844\u001B[0m   \u001B[1;31m# pylint: enable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6845\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\six.py\u001B[0m in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='ROC'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(1, 55)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_28 (Paramet (1, 40)              3880        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_29 (Paramet (1, 20)              1240        parameterizer_layer_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_30 (Paramet (1, 15)              555         parameterizer_layer_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "parameterizer_layer_31 (Paramet (1, 5)               110         parameterizer_layer_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (1, 55)              330         parameterizer_layer_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "relevances (Dropout)            (1, 55)              0           dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concepts (Lambda)               (1, 55)              0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (1, 55)              0           relevances[0][0]                 \n",
      "                                                                 concepts[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (1,)                 0           multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (1,)                 0           lambda_7[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,115\n",
      "Trainable params: 6,115\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9256), started 15:16:25 ago. (Use '!kill 9256' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2c815142e1ad437c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2c815142e1ad437c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize model in an interactive way\n",
    "#sadly only works until the preprocessing layers are over\n",
    "# tensorboard sometimes thinks there still is an instance running when it is not\n",
    "# fix that by deleting the contents of this folder or your equivalent of it\n",
    "# C:\\Users\\deisl\\AppData\\Local\\Temp\\.tensorboard-info\n",
    "\n",
    "%reload_ext tensorboard\n",
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZMnTKaCZda"
   },
   "source": [
    "## Inference on new data\n",
    "\n",
    "As the model contains all important parts, it should be able to work on any file of the right format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xkOlK8Zweeh"
   },
   "source": [
    "The model should be saved such that it can just be reloaded later.\\\n",
    "I will follow the tutorial [here](https://www.tensorflow.org/tutorials/keras/save_and_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.296839Z",
     "iopub.status.busy": "2020-09-17T01:33:52.296192Z",
     "iopub.status.idle": "2020-09-17T01:33:56.352943Z",
     "shell.execute_reply": "2020-09-17T01:33:56.352275Z"
    },
    "id": "QH9Zy1sBvwOH",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_pet_classifier\\assets\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: zero_loss",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-281-e23f75e80c7b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mfunctional_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'my_pet_classifier'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mreloaded_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'my_pet_classifier'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001B[0m in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[0;32m    185\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstring_types\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    186\u001B[0m       \u001B[0mloader_impl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse_saved_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 187\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msaved_model_load\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    188\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m   raise IOError(\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(path, compile, options)\u001B[0m\n\u001B[0;32m    128\u001B[0m         'training_config', None)\n\u001B[0;32m    129\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mtraining_config\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 130\u001B[1;33m       model.compile(**saving_utils.compile_args_from_training_config(\n\u001B[0m\u001B[0;32m    131\u001B[0m           training_config))\n\u001B[0;32m    132\u001B[0m       \u001B[0msaving_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtry_build_compiled_arguments\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py\u001B[0m in \u001B[0;36mcompile_args_from_training_config\u001B[1;34m(training_config, custom_objects)\u001B[0m\n\u001B[0;32m    215\u001B[0m     \u001B[0mloss_config\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtraining_config\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'loss'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    216\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mloss_config\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 217\u001B[1;33m       \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_deserialize_nested_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlosses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdeserialize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_config\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    218\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m     \u001B[1;31m# Recover metrics.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py\u001B[0m in \u001B[0;36m_deserialize_nested_config\u001B[1;34m(deserialize_fn, config)\u001B[0m\n\u001B[0;32m    258\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdeserialize_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    259\u001B[0m   \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 260\u001B[1;33m     return {\n\u001B[0m\u001B[0;32m    261\u001B[0m         \u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0m_deserialize_nested_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdeserialize_fn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    262\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py\u001B[0m in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    259\u001B[0m   \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    260\u001B[0m     return {\n\u001B[1;32m--> 261\u001B[1;33m         \u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0m_deserialize_nested_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdeserialize_fn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    262\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    263\u001B[0m     }\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py\u001B[0m in \u001B[0;36m_deserialize_nested_config\u001B[1;34m(deserialize_fn, config)\u001B[0m\n\u001B[0;32m    256\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    257\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0m_is_single_object\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 258\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mdeserialize_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    259\u001B[0m   \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    260\u001B[0m     return {\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\u001B[0m in \u001B[0;36mdeserialize\u001B[1;34m(name, custom_objects)\u001B[0m\n\u001B[0;32m   1848\u001B[0m       \u001B[0mA\u001B[0m \u001B[0mKeras\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mLoss\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0minstance\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0ma\u001B[0m \u001B[0mloss\u001B[0m \u001B[0mfunction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1849\u001B[0m   \"\"\"\n\u001B[1;32m-> 1850\u001B[1;33m   return deserialize_keras_object(\n\u001B[0m\u001B[0;32m   1851\u001B[0m       \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1852\u001B[0m       \u001B[0mmodule_objects\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mglobals\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001B[0m in \u001B[0;36mdeserialize_keras_object\u001B[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[0;32m    375\u001B[0m       \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule_objects\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    376\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 377\u001B[1;33m         raise ValueError(\n\u001B[0m\u001B[0;32m    378\u001B[0m             'Unknown ' + printable_module_name + ': ' + object_name)\n\u001B[0;32m    379\u001B[0m     \u001B[1;31m# Classes passed by name are instantiated with no args, functions are\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unknown loss function: zero_loss"
     ]
    }
   ],
   "source": [
    "functional_model.save('my_pet_classifier')\n",
    "reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D973plJrdwQ9"
   },
   "source": [
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are just two things you need to do:\n",
    "\n",
    "1.   Wrap scalars into a list so as to have a batch dimension (models only process batches of data, not single samples)\n",
    "2.   Call `convert_to_tensor` on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:56.360094Z",
     "iopub.status.busy": "2020-09-17T01:33:56.359400Z",
     "iopub.status.idle": "2020-09-17T01:33:56.669531Z",
     "shell.execute_reply": "2020-09-17T01:33:56.669015Z"
    },
    "id": "rKq4pxtdDa7i",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_keras_mask'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-284-0e472f34d072>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[0minput_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msample\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[0mprediction_example\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocesessing_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    983\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    984\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menable_auto_cast_variables\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 985\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    986\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    987\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    383\u001B[0m         \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m     \"\"\"\n\u001B[1;32m--> 385\u001B[1;33m     return self._run_internal_graph(\n\u001B[0m\u001B[0;32m    386\u001B[0m         inputs, training=training, mask=mask)\n\u001B[0;32m    387\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\deisl\\desktop\\thesis\\adaptation\\senn\\cudaenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    482\u001B[0m       \u001B[0mmasks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_flatten_to_reference_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    483\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0minput_t\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmask\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 484\u001B[1;33m       \u001B[0minput_t\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_keras_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    485\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    486\u001B[0m     \u001B[1;31m# Dictionary mapping reference tensors to computed tensors.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute '_keras_mask'"
     ]
    }
   ],
   "source": [
    "# TODO this does not work\n",
    "\n",
    "sample = {\n",
    "    'Type': 'Cat',\n",
    "    'Age': 3,\n",
    "    'Breed1': 'Tabby',\n",
    "    'Gender': 'Male',\n",
    "    'Color1': 'Black',\n",
    "    'Color2': 'White',\n",
    "    'MaturitySize': 'Small',\n",
    "    'FurLength': 'Short',\n",
    "    'Vaccinated': 'No',\n",
    "    'Sterilized': 'No',\n",
    "    'Health': 'Healthy',\n",
    "    'Fee': 100,\n",
    "    'PhotoAmt': 2,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "\n",
    "prediction_example = preprocesessing_model(sample)\n",
    "\n",
    "\n",
    "predictions = functional_model.predict(prediction_example)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "Old code for reference:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing_layers.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}